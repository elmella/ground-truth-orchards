{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import Birch\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_darkness(colors):\n",
    "    \"\"\"\n",
    "    Calculate darkness of each point. Assuming colors are in RGB format.\n",
    "    A simple approach is to average the RGB values, lower values indicating darkness.\n",
    "    \"\"\"\n",
    "    # Convert RGB to grayscale using luminosity method: 0.21 R + 0.72 G + 0.07 B\n",
    "    grayscale = 0.21 * colors[:, 0] + 0.72 * colors[:, 1] + 0.07 * colors[:, 2]\n",
    "    return grayscale\n",
    "\n",
    "def filter_by_darkness(colors, percentile_threshold):\n",
    "    \"\"\"\n",
    "    Filter points by darkness, using a specified percentile threshold.\n",
    "    \"\"\"\n",
    "    darkness = calculate_darkness(colors)\n",
    "    darkness_threshold = np.percentile(darkness, percentile_threshold)\n",
    "    # Indices of points darker than the threshold\n",
    "    return np.where(darkness <= darkness_threshold)[0]\n",
    "\n",
    "# Adjust brightness of the point cloud\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-3)\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    return np.clip(adjusted_colors, 0, 1)\n",
    "\n",
    "def calculate_brightness(colors):\n",
    "    # Simple average to define brightness\n",
    "    return np.mean(colors, axis=1)\n",
    "\n",
    "def adjust_layer_brightness(colors, target_brightness, z_coords, bins):\n",
    "    adjusted_colors = np.copy(colors)\n",
    "    # Bin z-coordinates to create layers\n",
    "    z_bins = np.digitize(z_coords, bins)\n",
    "    unique_bins = np.unique(z_bins)\n",
    "    \n",
    "    for bin in unique_bins:\n",
    "        # Identify points in the current bin/layer\n",
    "        in_bin = z_bins == bin\n",
    "        # Calculate current average brightness of the layer\n",
    "        current_avg_brightness = np.mean(calculate_brightness(colors[in_bin]))\n",
    "        # Calculate adjustment factor\n",
    "        adjustment_factor = target_brightness / current_avg_brightness\n",
    "        # Apply adjustment\n",
    "        adjusted_colors[in_bin] *= adjustment_factor\n",
    "        # Clip to valid range\n",
    "        adjusted_colors[in_bin] = np.clip(adjusted_colors[in_bin], 0, 255)\n",
    "    \n",
    "    return adjusted_colors\n",
    "\n",
    "# def is_grey(color, threshold=1):\n",
    "#     \"\"\"\n",
    "#     Determine if a color is grey based on the RGB components being within a threshold.\n",
    "#     \"\"\"\n",
    "#     r, g, b = color\n",
    "#     max_diff = np.max(np.abs(np.array([r, g, b]) - np.mean([r, g, b])))\n",
    "#     return max_diff <= threshold\n",
    "\n",
    "def is_grey(colors, threshold=0.02):\n",
    "    \"\"\"\n",
    "    Vectorized check if colors are grey, based on the RGB components being within a threshold.\n",
    "    \"\"\"\n",
    "    # Calculate the mean across the RGB channels\n",
    "    mean_colors = np.mean(colors, axis=1, keepdims=True)\n",
    "    # Calculate the maximum absolute difference from the mean for each color\n",
    "    max_diff = np.max(np.abs(colors - mean_colors), axis=1)\n",
    "    # Identify grey colors based on the threshold\n",
    "    grey_mask = max_diff <= threshold\n",
    "    return grey_mask\n",
    "\n",
    "def calculate_greyness(colors):\n",
    "    \"\"\"\n",
    "    Calculate the 'greyness' of each color by finding the standard deviation of the RGB components.\n",
    "    Lower standard deviation means the color is closer to grey.\n",
    "    \"\"\"\n",
    "    # Standard deviation among R, G, B components for each point\n",
    "    std_deviation = np.std(colors, axis=1)\n",
    "    return std_deviation\n",
    "\n",
    "def oversaturate_colors(colors_rgb):\n",
    "    \"\"\"\n",
    "    Oversaturate the colors of the point cloud.\n",
    "    Colors are assumed to be in [0, 1] range.\n",
    "    \"\"\"\n",
    "    # Convert RGB to HSV\n",
    "    colors_hsv = rgb_to_hsv(colors_rgb)\n",
    "    \n",
    "    # Increase saturation; ensure it does not exceed 1\n",
    "    colors_hsv[:, 1] = np.clip(colors_hsv[:, 1] * 12, 0, 1)  # Increase saturation by 50%\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    colors_rgb_oversaturated = hsv_to_rgb(colors_hsv)\n",
    "    \n",
    "    return colors_rgb_oversaturated\n",
    "\n",
    "def aggregate_covariances(pcd, radius=0.1, min_neighbors=10):\n",
    "    \"\"\"\n",
    "    Aggregate covariance matrices for each point based on neighbors within a specified radius.\n",
    "    Only considers points with a minimum number of neighbors to ensure meaningful local geometry.\n",
    "    \"\"\"\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "    aggregated_covariances = []\n",
    "    valid_indices = []  # To track indices of points with sufficient neighbors\n",
    "    for i in range(len(pcd.points)):\n",
    "        [_, idx, _] = kdtree.search_radius_vector_3d(pcd.points[i], radius)\n",
    "        if len(idx) >= min_neighbors:  # Check against min_neighbors threshold\n",
    "            neighbors = np.asarray(pcd.points)[idx]\n",
    "            cov_matrix = np.cov(neighbors.T)\n",
    "            aggregated_covariances.append(cov_matrix)\n",
    "            valid_indices.append(i)\n",
    "        else:  # Ignore points that do not meet the neighbor threshold\n",
    "            continue\n",
    "    return np.array(aggregated_covariances), np.array(valid_indices)\n",
    "\n",
    "def compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances):\n",
    "    eigenvalues = np.zeros((len(aggregated_covariances), 3))\n",
    "    eigenvectors = np.zeros((len(aggregated_covariances), 3, 3))\n",
    "    for i, cov in enumerate(aggregated_covariances):\n",
    "        e_vals, e_vecs = np.linalg.eigh(cov)\n",
    "        eigenvalues[i] = e_vals\n",
    "        eigenvectors[i] = e_vecs\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "def detect_bifurcation_points_with_layer_filtering(eigenvalues, valid_indices, layers, distance_percentile, covariance_percentile):\n",
    "    # Calculate the ratios of the smallest to largest eigenvalues\n",
    "    ratios = eigenvalues[:, 2] / eigenvalues[:, 0]\n",
    "\n",
    "    # Calculate the dynamic threshold\n",
    "    # threshold = np.percentile(ratios, covariance_percentile)\n",
    "\n",
    "    # Create a mapping from original indices to filtered indices\n",
    "    index_mapping = {original_index: filtered_index for filtered_index, original_index in enumerate(valid_indices)}\n",
    "\n",
    "    # Adjust bifurcation_indices to be valid for the ratios array\n",
    "    adjusted_bifurcation_indices = np.array([index_mapping.get(index, -1) for index in valid_indices])\n",
    "\n",
    "    # Remove any indices that couldn't be mapped (-1)\n",
    "    adjusted_bifurcation_indices = adjusted_bifurcation_indices[adjusted_bifurcation_indices != -1]\n",
    "\n",
    "    # Apply threshold to filter bifurcation points\n",
    "    is_bifurcation = ratios <= 1.4\n",
    "    bifurcation_indices = adjusted_bifurcation_indices[is_bifurcation[adjusted_bifurcation_indices]]\n",
    "\n",
    "    return bifurcation_indices\n",
    "\n",
    "def detect_bifurcation_points(eigenvalues, valid_indices, percentile_threshold):\n",
    "    \"\"\"\n",
    "    Detect bifurcation points based on the eigenvalues of the aggregated covariances.\n",
    "    \"\"\"\n",
    "    # Calculate the ratios of the smallest to largest eigenvalues\n",
    "    ratios = eigenvalues[:, 2] / eigenvalues[:, 0]\n",
    "\n",
    "    # Create a mapping from original indices to filtered indices\n",
    "    index_mapping = {original_index: filtered_index for filtered_index, original_index in enumerate(valid_indices)}\n",
    "\n",
    "    # Adjust bifurcation_indices to be valid for the ratios array\n",
    "    adjusted_bifurcation_indices = np.array([index_mapping.get(index, -1) for index in valid_indices])\n",
    "\n",
    "    # Remove any indices that couldn't be mapped (-1)\n",
    "    adjusted_bifurcation_indices = adjusted_bifurcation_indices[adjusted_bifurcation_indices != -1]\n",
    "\n",
    "    # Apply threshold to filter bifurcation points\n",
    "    is_bifurcation = ratios <= 1.4\n",
    "    bifurcation_indices = adjusted_bifurcation_indices[is_bifurcation[adjusted_bifurcation_indices]]\n",
    "\n",
    "    return bifurcation_indices\n",
    "\n",
    "\n",
    "\n",
    "def split_into_layers(pcd, num_layers=20):\n",
    "    \"\"\"\n",
    "    Split the point cloud into specified number of z layers.\n",
    "    Calculate distance from the mean (x, y) position of each layer for each point.\n",
    "    \"\"\"\n",
    "    z_values = np.asarray(pcd.points)[:, 2]\n",
    "    z_min, z_max = np.min(z_values), np.max(z_values)\n",
    "    layer_bounds = np.linspace(z_min, z_max, num_layers + 1)\n",
    "    layers = {}\n",
    "    for i in range(num_layers):\n",
    "        layer_indices = np.where((z_values >= layer_bounds[i]) & (z_values < layer_bounds[i+1]))[0]\n",
    "        if len(layer_indices) > 0:\n",
    "            layer_points = np.asarray(pcd.points)[layer_indices]\n",
    "            mean_x, mean_y = np.mean(layer_points[:, 0]), np.mean(layer_points[:, 1])\n",
    "            # Calculate distance from the layer's mean (x, y) position\n",
    "            distances = np.sqrt((layer_points[:, 0] - mean_x)**2 + (layer_points[:, 1] - mean_y)**2)\n",
    "            layers[i] = {\n",
    "                \"indices\": layer_indices,\n",
    "                \"distances\": distances\n",
    "            }\n",
    "    return layers\n",
    "\n",
    "def filter_points_by_distance(layers, percentile_threshold):\n",
    "    \"\"\"\n",
    "    Filter points in each layer based on their distance from the layer's mean (x, y) position,\n",
    "    using a percentile threshold.\n",
    "    \"\"\"\n",
    "    valid_points_indices = []\n",
    "    for layer in layers.values():\n",
    "        distance_threshold = np.percentile(layer[\"distances\"], percentile_threshold)\n",
    "        valid_indices = layer[\"indices\"][layer[\"distances\"] <= distance_threshold]\n",
    "        valid_points_indices.extend(valid_indices)\n",
    "    return np.array(valid_points_indices)\n",
    "\n",
    "def calculate_darkness(colors):\n",
    "    \"\"\"\n",
    "    Calculate darkness of each point. Assuming colors are in RGB format.\n",
    "    A simple approach is to average the RGB values, lower values indicating darkness.\n",
    "    \"\"\"\n",
    "    # Convert RGB to grayscale using luminosity method: 0.21 R + 0.72 G + 0.07 B\n",
    "    grayscale = 0.21 * colors[:, 0] + 0.72 * colors[:, 1] + 0.07 * colors[:, 2]\n",
    "    return grayscale\n",
    "\n",
    "def filter_by_darkness(colors, percentile_threshold):\n",
    "    \"\"\"\n",
    "    Filter points by darkness, using a specified percentile threshold.\n",
    "    \"\"\"\n",
    "    darkness = calculate_darkness(colors)\n",
    "    darkness_threshold = np.percentile(darkness, percentile_threshold)\n",
    "    # Indices of points darker than the threshold\n",
    "    return np.where(darkness <= darkness_threshold)[0]\n",
    "\n",
    "def find_and_color_neighbors(pcd, bifurcation_indices, num_neighbors=5):\n",
    "    \"\"\"\n",
    "    For each bifurcation point, find and color the nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Convert Open3D PointCloud to NumPy array for easier manipulation\n",
    "    pcd_points = np.asarray(pcd.points)\n",
    "    pcd_colors = np.asarray(pcd.colors)\n",
    "    \n",
    "    # Ensure colors array exists\n",
    "    if pcd_colors.shape[0] != pcd_points.shape[0]:\n",
    "        pcd_colors = np.zeros_like(pcd_points)  # Initialize with zeros if colors are not set\n",
    "\n",
    "    # Build KDTree for efficient neighbor search\n",
    "    kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    for bifurcation_idx in bifurcation_indices:\n",
    "        # Search for nearest neighbors\n",
    "        [k, idx, _] = kdtree.search_knn_vector_3d(pcd_points[bifurcation_idx], num_neighbors + 1)  # +1 to include self\n",
    "        # Color neighbors red, excluding the bifurcation point itself\n",
    "        for i in range(1, k):  # start from 1 to exclude the bifurcation point itself\n",
    "            pcd_colors[idx[i]] = [1, 0, 0]  # Red\n",
    "\n",
    "    # Update colors in the original point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(pcd_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[========================================] 100%\n",
      "Clustering[==================================>     ] 85%\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 23393 is out of bounds for axis 0 with size 23393",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Detect bifurcation points with layer-based filtering\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m bifurcation_indices \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_bifurcation_points_with_layer_filtering\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentile_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Visualize bifurcation points\u001b[39;00m\n\u001b[1;32m     85\u001b[0m colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(pcd\u001b[38;5;241m.\u001b[39mcolors)\n",
      "Cell \u001b[0;32mIn[24], line 53\u001b[0m, in \u001b[0;36mdetect_bifurcation_points_with_layer_filtering\u001b[0;34m(eigenvalues, valid_indices, layers, percentile_threshold)\u001b[0m\n\u001b[1;32m     50\u001b[0m valid_layer_filtered_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mintersect1d(valid_indices, layer_filtered_indices)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Further filter by eigenvalue ratio threshold\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m final_indices \u001b[38;5;241m=\u001b[39m valid_layer_filtered_indices[\u001b[43mratios\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_layer_filtered_indices\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_indices\n",
      "\u001b[0;31mIndexError\u001b[0m: index 23393 is out of bounds for axis 0 with size 23393"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def split_into_layers(pcd, num_layers=20):\n",
    "    \"\"\"\n",
    "    Split the point cloud into specified number of z layers.\n",
    "    Calculate distance from the mean (x, y) position of each layer for each point.\n",
    "    \"\"\"\n",
    "    z_values = np.asarray(pcd.points)[:, 2]\n",
    "    z_min, z_max = np.min(z_values), np.max(z_values)\n",
    "    layer_bounds = np.linspace(z_min, z_max, num_layers + 1)\n",
    "    layers = {}\n",
    "    for i in range(num_layers):\n",
    "        layer_indices = np.where((z_values >= layer_bounds[i]) & (z_values < layer_bounds[i+1]))[0]\n",
    "        if len(layer_indices) > 0:\n",
    "            layer_points = np.asarray(pcd.points)[layer_indices]\n",
    "            mean_x, mean_y = np.mean(layer_points[:, 0]), np.mean(layer_points[:, 1])\n",
    "            # Calculate distance from the layer's mean (x, y) position\n",
    "            distances = np.sqrt((layer_points[:, 0] - mean_x)**2 + (layer_points[:, 1] - mean_y)**2)\n",
    "            layers[i] = {\n",
    "                \"indices\": layer_indices,\n",
    "                \"distances\": distances\n",
    "            }\n",
    "    return layers\n",
    "\n",
    "def filter_points_by_distance(layers, percentile_threshold):\n",
    "    \"\"\"\n",
    "    Filter points in each layer based on their distance from the layer's mean (x, y) position,\n",
    "    using a percentile threshold.\n",
    "    \"\"\"\n",
    "    valid_points_indices = []\n",
    "    for layer in layers.values():\n",
    "        distance_threshold = np.percentile(layer[\"distances\"], percentile_threshold)\n",
    "        valid_indices = layer[\"indices\"][layer[\"distances\"] <= distance_threshold]\n",
    "        valid_points_indices.extend(valid_indices)\n",
    "    return np.array(valid_points_indices)\n",
    "\n",
    "# Function to detect bifurcation points with layer-based filtering applied only for bifurcation analysis\n",
    "def detect_bifurcation_points_with_layer_filtering(eigenvalues, valid_indices, layers, percentile_threshold):\n",
    "    \"\"\"\n",
    "    Detect bifurcation points based on eigenvalue ratios, applying layer-based distance filtering\n",
    "    only for the purpose of bifurcation point analysis.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-8  # To avoid division by zero\n",
    "    ratios = eigenvalues[:, 2] / (eigenvalues[:, 0] + epsilon)\n",
    "    valid_ratios = np.isfinite(ratios)\n",
    "    \n",
    "    # Filter points based on distance from origin within their Z layer using the specified percentile\n",
    "    layer_filtered_indices = filter_points_by_distance(layers, percentile_threshold)\n",
    "    \n",
    "    # Apply the dynamic threshold based on eigenvalue ratios\n",
    "    threshold = np.percentile(ratios[valid_ratios], 10)  # Use a dynamic percentile for the threshold\n",
    "    bifurcation_indices = np.intersect1d(valid_indices, layer_filtered_indices)\n",
    "\n",
    "    # Correctly filter bifurcation_indices based on the threshold\n",
    "    # Remove the incorrect double-indexing of ratios\n",
    "    filtered_ratios = ratios[bifurcation_indices]  # Get the ratios for the filtered indices only once\n",
    "    bifurcation_indices_filtered = bifurcation_indices[filtered_ratios <= threshold]  # Filter indices based on threshold\n",
    "\n",
    "    return bifurcation_indices_filtered\n",
    "\n",
    "\n",
    "# Load and preprocess the point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"3d-forest-classic-data/tree_1.pcd\")\n",
    "# pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "# Noise removal and normal estimation\n",
    "labels = np.array(pcd.cluster_dbscan(eps=0.1, min_points=5, print_progress=True))\n",
    "inliers = np.where(labels != -1)\n",
    "pcd = pcd.select_by_index(inliers[0])\n",
    "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Estimate covariances for the entire point cloud\n",
    "pcd.estimate_covariances(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Split into layers for distance-based filtering\n",
    "layers = split_into_layers(pcd, num_layers=20)\n",
    "\n",
    "# Aggregate covariances for each point\n",
    "aggregated_covariances, valid_indices = aggregate_covariances(pcd, radius=0.1, min_neighbors=10)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors from the aggregated covariances\n",
    "eigenvalues, eigenvectors = compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n",
    "\n",
    "# Detect bifurcation points with layer-based filtering\n",
    "bifurcation_indices = detect_bifurcation_points_with_layer_filtering(eigenvalues, valid_indices, layers, percentile_threshold=50)\n",
    "\n",
    "# Visualize bifurcation points\n",
    "colors = np.asarray(pcd.colors)\n",
    "if len(colors) == 0:\n",
    "    colors = np.zeros((len(pcd.points), 3))\n",
    "colors[bifurcation_indices] = [1, 0, 0]  # Red for bifurcation points\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the entire point cloud with highlighted bifurcation points\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[========================================] 100%\n",
      "619stering[=====================================>  ] 92%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Load the point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"aligned_tree.pcd\")\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Adjust brightness if needed\n",
    "target_brightness = np.mean(calculate_brightness(colors))\n",
    "adjusted_colors = adjust_brightness(colors, target_brightness)\n",
    "colors = adjusted_colors\n",
    "\n",
    "# Calculate greyness for each point\n",
    "greyness = calculate_greyness(adjusted_colors)\n",
    "\n",
    "# Determine the 60th percentile greyness threshold\n",
    "greyness_threshold = np.percentile(greyness, 85)\n",
    "\n",
    "# Identify grey and non-grey points\n",
    "grey_mask = is_grey(adjusted_colors, threshold=greyness_threshold)\n",
    "grey_indices = np.where(grey_mask)[0]\n",
    "nongrey_indices = np.where(~grey_mask)[0]\n",
    "\n",
    "# Create and visualize grey points cloud\n",
    "grey_pcd = o3d.geometry.PointCloud()\n",
    "grey_pcd.points = o3d.utility.Vector3dVector(points[grey_indices])\n",
    "grey_pcd.colors = o3d.utility.Vector3dVector(adjusted_colors[grey_indices])\n",
    "\n",
    "# o3d.visualization.draw_geometries([grey_pcd], window_name=\"Grey Points\")\n",
    "\n",
    "# Create and visualize non-grey points cloud\n",
    "nongrey_pcd = o3d.geometry.PointCloud()\n",
    "nongrey_pcd.points = o3d.utility.Vector3dVector(points[nongrey_indices])\n",
    "nongrey_pcd.colors = o3d.utility.Vector3dVector(adjusted_colors[nongrey_indices])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(adjusted_colors[nongrey_indices])\n",
    "green_label = np.argmax([np.mean(adjusted_colors[nongrey_indices][kmeans.labels_ == i, 1]) for i in range(2)])\n",
    "\n",
    "# visualize the green points\n",
    "green_pcd = o3d.geometry.PointCloud()\n",
    "green_pcd.points = o3d.utility.Vector3dVector(points[nongrey_indices][kmeans.labels_ == green_label])\n",
    "green_pcd.colors = o3d.utility.Vector3dVector(adjusted_colors[nongrey_indices][kmeans.labels_ == green_label])\n",
    "# o3d.visualization.draw_geometries([green_pcd], window_name=\"Green Points\")\n",
    "\n",
    "# Apply DBSCAN clustering and get labels\n",
    "labels = np.array(green_pcd.cluster_dbscan(eps=0.01, min_points=7, print_progress=True))\n",
    "\n",
    "# Create a color map (you can use any color map you like)\n",
    "color_map = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# Assign each label a unique color\n",
    "label_colors = color_map(labels / np.max(labels))\n",
    "\n",
    "# Create a new point cloud for the labeled points\n",
    "labeled_pcd = o3d.geometry.PointCloud()\n",
    "labeled_pcd.points = o3d.utility.Vector3dVector(points[nongrey_indices][kmeans.labels_ == green_label])\n",
    "\n",
    "# Only take the RGB values of the colors\n",
    "labeled_pcd.colors = o3d.utility.Vector3dVector(label_colors[:, :3])\n",
    "\n",
    "# print number of clusters\n",
    "print(np.max(labels))\n",
    "\n",
    "# Visualize the labeled points\n",
    "o3d.visualization.draw_geometries([labeled_pcd], window_name=\"Labeled Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"aligned_tree.pcd\")\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Filter points by darkness\n",
    "filtered_indices = filter_by_darkness(colors, 25)\n",
    "filtered_points = points[filtered_indices]\n",
    "filtered_colors = colors[filtered_indices]\n",
    "\n",
    "# filtered_points = points\n",
    "# filtered_colors = colors\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "\n",
    "# Calculate target brightness\n",
    "target_brightness = np.mean(np.mean(filtered_colors, axis=0))\n",
    "\n",
    "# Adjust brightness\n",
    "adjusted_colors = adjust_brightness(filtered_colors, target_brightness)\n",
    "\n",
    "colors = adjusted_colors\n",
    "\n",
    "# Assuming 'colors' are in [0, 1] range. If they're in [0, 255], normalize them first.\n",
    "colors_normalized = colors / 255.0 if np.max(colors) > 1 else colors\n",
    "\n",
    "# Oversaturate colors\n",
    "colors = oversaturate_colors(colors_normalized)\n",
    "\n",
    "# visualize the adjusted point cloud\n",
    "adjusted_pcd = o3d.geometry.PointCloud()\n",
    "adjusted_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "adjusted_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "o3d.visualization.draw_geometries([adjusted_pcd], window_name=\"Adjusted Point Cloud\")\n",
    "\n",
    "\n",
    "# visualize the adjusted point cloud\n",
    "adjusted_pcd = o3d.geometry.PointCloud()\n",
    "adjusted_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "adjusted_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([adjusted_pcd], window_name=\"Adjusted Point Cloud\")\n",
    "\n",
    "# downsample the point cloud\n",
    "# downsampled_pcd = adjusted_pcd.voxel_down_sample(voxel_size=0.001)\n",
    "pcd = adjusted_pcd\n",
    "colors = np.asarray(pcd.colors)\n",
    "points = np.asarray(pcd.points)\n",
    "\n",
    "greyness = calculate_greyness(colors)\n",
    "\n",
    "# Determine the 60th percentile greyness threshold\n",
    "greyness_threshold = np.percentile(greyness, 30)\n",
    "\n",
    "# Filter points that are grey based on the greyness threshold\n",
    "# Points with greyness less than or equal to the threshold are considered grey\n",
    "grey_mask = greyness <= greyness_threshold\n",
    "grey_indices = np.where(grey_mask)[0]\n",
    "nongrey_indices = np.where(~grey_mask)[0]\n",
    "\n",
    "# Create and visualize grey points cloud\n",
    "grey_pcd = o3d.geometry.PointCloud()\n",
    "grey_pcd.points = o3d.utility.Vector3dVector(points[grey_indices])\n",
    "grey_pcd.colors = o3d.utility.Vector3dVector(colors[grey_indices])  # Convert back if needed\n",
    "\n",
    "# Visualization for grey points\n",
    "o3d.visualization.draw_geometries([grey_pcd], window_name=\"Grey Points\")\n",
    "\n",
    "# Create a new point cloud for non-grey points\n",
    "nongrey_pcd = o3d.geometry.PointCloud()\n",
    "nongrey_pcd.points = o3d.utility.Vector3dVector(points[nongrey_indices])\n",
    "nongrey_pcd.colors = o3d.utility.Vector3dVector(colors[nongrey_indices])\n",
    "\n",
    "# Visualization\n",
    "o3d.visualization.draw_geometries([nongrey_pcd], window_name=\"Non-grey Points\")\n",
    "# labels = np.array(pcd.cluster_dbscan(eps=0.006, min_points=10, print_progress=True))\n",
    "# max_label = labels.max()\n",
    "# print(f\"point cloud has {max_label + 1} clusters\")\n",
    "\n",
    "# # visualize the clustered point cloud\n",
    "# clusters = []\n",
    "# for i in range(max_label + 1):\n",
    "#     cluster = pcd.select_by_index(np.where(labels == i)[0])\n",
    "#     if len(cluster.points) > 1000:\n",
    "#         clusters += [cluster]\n",
    "# print(f\"point cloud has {len(clusters)} clusters\")\n",
    "\n",
    "# cluster_pcd = o3d.geometry.PointCloud()\n",
    "# cluster_pcd.points = o3d.utility.Vector3dVector(np.concatenate([np.asarray(cluster.points) for cluster in clusters]))\n",
    "# cluster_pcd.colors = o3d.utility.Vector3dVector(np.concatenate([np.asarray(cluster.colors) for cluster in clusters]))\n",
    "\n",
    "# classes = 10\n",
    "# cluster_points = np.asarray(cluster_pcd.points)\n",
    "# cluster_colors = np.asarray(cluster_pcd.colors)\n",
    "# kmeans = KMeans(n_clusters=classes, random_state=0).fit(cluster_colors)\n",
    "# kmeans_labels = kmeans.labels_\n",
    "\n",
    "\n",
    "# # green_label = np.argmax([np.mean(cluster_colors[np.where(kmeans_labels == i)], axis=0)[1] for i in range(classes)])\n",
    "\n",
    "# greener_labels = np.argsort([np.mean(cluster_colors[np.where(kmeans_labels == i)], axis=0)[1] for i in range(classes)])[::-1][:classes // 3]\n",
    "\n",
    "# greener_indices = np.concatenate([np.where(kmeans_labels == i)[0] for i in greener_labels])\n",
    "# non_greener_indices = np.concatenate([np.where(kmeans_labels == i)[0] for i in range(classes) if i not in greener_labels])\n",
    "\n",
    "# # visualize the clustered point cloud\n",
    "# # for i in range(classes):\n",
    "# o3d.visualization.draw_geometries([cluster_pcd.select_by_index(greener_indices)], window_name=\"Clustered Point Cloud\")\n",
    "# o3d.visualization.draw_geometries([cluster_pcd.select_by_index(non_greener_indices)], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # o3d.visualization.draw_geometries([cluster_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 108\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"aligned_tree.pcd\")\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Step 1: Determine Vertical Range\n",
    "z_coords = points[:, 2]  # Assuming the third column represents the z-coordinate\n",
    "min_z, max_z = np.min(z_coords), np.max(z_coords)\n",
    "\n",
    "# Determine vertical range and create bins for layers\n",
    "num_bins = 15  # Adjust the number of bins as needed for granularity\n",
    "z_bins = np.linspace(min_z, max_z, num=num_bins+1)\n",
    "\n",
    "# Calculate overall target brightness (you might adjust this strategy)\n",
    "target_brightness = np.mean(calculate_brightness(colors))\n",
    "\n",
    "# Apply adjustment\n",
    "adjusted_colors = adjust_layer_brightness(colors, target_brightness, z_coords, z_bins)\n",
    "\n",
    "# Replace original colors with adjusted colors for further processing\n",
    "colors = adjusted_colors\n",
    "\n",
    "# Filter points by darkness\n",
    "filtered_indices = filter_by_darkness(colors, 5)\n",
    "filtered_points = points[filtered_indices]\n",
    "filtered_colors = colors[filtered_indices]\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "\n",
    "# Calculate target brightness\n",
    "target_brightness = np.mean(np.mean(filtered_colors, axis=0))\n",
    "\n",
    "# Adjust brightness\n",
    "adjusted_colors = adjust_brightness(filtered_colors, target_brightness)\n",
    "# Step 1 & 2: Standardize Features and Combine with Emphasis on Color\n",
    "scaler = StandardScaler()\n",
    "scaled_points = scaler.fit_transform(filtered_points)  # Standardize positions\n",
    "scaled_colors = scaler.fit_transform(adjusted_colors) * 2  # Standardize colors and weigh more heavily\n",
    "\n",
    "combined_features = np.hstack((scaled_points, scaled_colors))  # Combine standardized features\n",
    "\n",
    "# Step 3: DBSCAN Clustering on Combined Features\n",
    "dbscan = DBSCAN(eps=0.28, min_samples=10).fit(combined_features)  # Adjust eps and min_samples as needed\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Identify the number of clusters (ignoring noise points, if any)\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"Estimated number of clusters: {n_clusters_}\")\n",
    "\n",
    "# Step 4: Visualization\n",
    "# Create a copy of the original point cloud for visualization\n",
    "viz_pcd = o3d.geometry.PointCloud()\n",
    "viz_pcd.points = o3d.utility.Vector3dVector(points)  # Use original points\n",
    "viz_pcd.colors = o3d.utility.Vector3dVector(colors)  # Use original colors initially\n",
    "\n",
    "# Assign colors based on DBSCAN labels\n",
    "unique_labels = set(labels)\n",
    "# Create a new colors array for the original point cloud with default color\n",
    "new_colors = np.array(viz_pcd.colors)\n",
    "\n",
    "# Prepare a colormap\n",
    "colors_per_cluster = plt.cm.get_cmap(\"hsv\", len(unique_labels) + 1)(range(len(unique_labels) + 1))\n",
    "\n",
    "# Apply colors based on labels to the filtered points only\n",
    "for k, col in zip(unique_labels, colors_per_cluster):\n",
    "    if k == -1:  # Noise\n",
    "        col = [0, 0, 0, 1]  # Black for noise\n",
    "    # Use filtered indices to find the positions in the original point cloud that correspond to each label\n",
    "    match_indices = np.where(labels == k)[0]\n",
    "    if len(match_indices) > 100:\n",
    "        new_colors[filtered_indices[match_indices], :] = col[:3]\n",
    "\n",
    "# Update the colors of the original point cloud for visualization\n",
    "viz_pcd.colors = o3d.utility.Vector3dVector(new_colors)\n",
    "\n",
    "# Visualization\n",
    "o3d.visualization.draw_geometries([viz_pcd], window_name=\"Clustered Point Cloud with Original Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257045\n",
      "128525\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"branch_points.pcd\")\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "print(len(points))\n",
    "\n",
    "    # remove outliers left from the plane segmentation\n",
    "clf = IsolationForest(contamination=0.5)\n",
    "clf.fit(points)\n",
    "y_pred = clf.predict(points)\n",
    "outliers = np.where(y_pred == -1)\n",
    "inliers = np.where(y_pred == 1)\n",
    "points = np.delete(points, outliers, axis=0)\n",
    "colors = np.delete(colors, outliers, axis=0)\n",
    "print(len(points))\n",
    "\n",
    "    # remove outliers left from the plane segmentation\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "# visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[========================================] 100%\n",
      "point cloud has 3058 clusters=============>        ] 77%\n",
      "62316\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "detect_bifurcation_points_with_layer_filtering() got an unexpected keyword argument 'covariance_percentile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Detect bifurcation points on the filtered subset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m bifurcation_indices \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_bifurcation_points_with_layer_filtering\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_percentile_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariance_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Color a few nearest points to each bifurcation point red\u001b[39;00m\n\u001b[1;32m     40\u001b[0m find_and_color_neighbors(filtered_pcd, bifurcation_indices, num_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: detect_bifurcation_points_with_layer_filtering() got an unexpected keyword argument 'covariance_percentile'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"aligned_tree.pcd\")\n",
    "pcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# dbscan to remove noise\n",
    "labels = np.array(pcd.cluster_dbscan(eps=0.005, min_points=5, print_progress=True))\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "\n",
    "# Remove noise\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "inliers = np.where(labels != -1)\n",
    "print(len(inliers[0]))\n",
    "points = points[inliers]\n",
    "colors = colors[inliers]\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Apply darkness and distance filters\n",
    "darkness_percentile_threshold = 55  # Adjust based on preference\n",
    "dark_points_indices = filter_by_darkness(np.asarray(pcd.colors), darkness_percentile_threshold)\n",
    "\n",
    "layers = split_into_layers(pcd, num_layers=40)\n",
    "distance_percentile_threshold = 60  # Adjust based on preference\n",
    "distance_filtered_indices = filter_points_by_distance(layers, distance_percentile_threshold)\n",
    "\n",
    "# Combine filters: only consider points passing both darkness and distance filters\n",
    "combined_filtered_indices = np.intersect1d(dark_points_indices, distance_filtered_indices)\n",
    "\n",
    "# Proceed with aggregate_covariances and subsequent steps on the filtered points\n",
    "filtered_pcd = pcd.select_by_index(combined_filtered_indices)\n",
    "aggregated_covariances, valid_indices = aggregate_covariances(filtered_pcd, radius=0.1, min_neighbors=20)\n",
    "eigenvalues, eigenvectors = compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n",
    "\n",
    "# Detect bifurcation points on the filtered subset\n",
    "bifurcation_indices = detect_bifurcation_points_with_layer_filtering(eigenvalues, valid_indices, layers, distance_percentile_threshold, covariance_percentile=5)\n",
    "\n",
    "# Color a few nearest points to each bifurcation point red\n",
    "find_and_color_neighbors(filtered_pcd, bifurcation_indices, num_neighbors=5)\n",
    "\n",
    "# Visualize the filtered point cloud with highlighted neighbors of bifurcation points\n",
    "o3d.visualization.draw_geometries([filtered_pcd], window_name=\"Filtered Point Cloud with Highlighted Neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point cloud has 1016 clusters                                 ] 2%\n",
      "21787\n",
      "Precompute neighbors.[========================================] 100%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your processed point cloud\n",
    "# pcd = o3d.io.read_point_cloud(\"3d-forest-classic-data/tree_1.pcd\")\n",
    "pcd = o3d.io.read_point_cloud(\"aligned_tree.pcd\")\n",
    "\n",
    "#downsample the point cloud\n",
    "pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "# dbscan to remove noise\n",
    "labels = np.array(pcd.cluster_dbscan(eps=0.01, min_points=5, print_progress=True))\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "\n",
    "# Remove noise\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "inliers = np.where(labels != -1)\n",
    "print(len(inliers[0]))\n",
    "points = points[inliers]\n",
    "colors = colors[inliers]\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "\n",
    "# Estimate normals\n",
    "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "# Estimate covariances\n",
    "pcd.estimate_covariances(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "# Aggregate covariances\n",
    "# Adjust your point cloud processing to include these modifications:\n",
    "aggregated_covariances, valid_indices = aggregate_covariances(pcd, radius=0.1, min_neighbors=10)\n",
    "eigenvalues, eigenvectors = compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n",
    "\n",
    "bifurcation_indices = detect_bifurcation_points(eigenvalues, valid_indices, percentile_threshold=5)\n",
    "\n",
    "# Visualize bifurcation points (setting them as red)\n",
    "colors = np.asarray(pcd.colors)\n",
    "if len(colors) == 0:\n",
    "    colors = np.zeros((len(pcd.points), 3))\n",
    "colors[bifurcation_indices] = [1, 0, 0]  # Red\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the point cloud with bifurcation points highlighted\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[===============>             point cloud has 165 clusters\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Precompute neighbors.[========================================] 100%\n",
      "0lustering[===========================>            ] 67%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"3d-forest-classic-data/tree_3.pcd\")\n",
    "points = np.asarray(pcd.points)\n",
    "\n",
    "# detect bifurcation points\n",
    "labels = np.array(pcd.cluster_dbscan(eps=0.105, min_points=10, print_progress=True))\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "\n",
    "# remove noise\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "inliers = np.where(labels != -1)\n",
    "points = points[inliers]\n",
    "\n",
    "# Estimate normals\n",
    "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "# Estimate covariances\n",
    "pcd.estimate_covariances(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# visualize the point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Filtered Point Cloud\")\n",
    "\n",
    "# Aggregate covariances\n",
    "aggregated_covariances, valid_indices = aggregate_covariances(pcd, radius=1, min_neighbors=5)\n",
    "eigenvalues, eigenvectors = compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n",
    "\n",
    "bifurcation_indices = detect_bifurcation_points(eigenvalues, valid_indices, percentile_threshold=0)\n",
    "\n",
    "print(len(bifurcation_indices))\n",
    "\n",
    "# Visualize bifurcation points (setting them as red)\n",
    "colors = np.zeros((len(pcd.points), 3))\n",
    "colors = np.zeros((len(pcd.points), 3))\n",
    "colors[bifurcation_indices] = [1, 0, 0]  # Red\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the point cloud with bifurcation points highlighted\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[========================================] 100%\n",
      "[ 2.65006385 14.09401293  8.86118115 ...  6.36345604  5.46918539\n",
      "  2.73384803]\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"branch_points.pcd\")\n",
    "\n",
    "# DBSCAN clustering\n",
    "labels = np.array(pcd.cluster_dbscan(eps=0.004, min_points=5, print_progress=True))\n",
    "\n",
    "# Find the label with the most points\n",
    "counts = np.bincount(labels[labels >= 0])\n",
    "largest_group_label = counts.argmax()\n",
    "\n",
    "# Create a new point cloud with only the points from the largest group\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "largest_group_points = points[labels == largest_group_label]\n",
    "largest_group_colors = colors[labels == largest_group_label]\n",
    "\n",
    "largest_group_pcd = o3d.geometry.PointCloud()\n",
    "largest_group_pcd.points = o3d.utility.Vector3dVector(largest_group_points)\n",
    "largest_group_pcd.colors = o3d.utility.Vector3dVector(largest_group_colors)\n",
    "\n",
    "#downsample the point cloud\n",
    "largest_group_pcd = largest_group_pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# Estimate the normals for the largest group point cloud\n",
    "largest_group_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.05, max_nn=30))\n",
    "# largest_group_pcd.orient_normals_consistent_tangent_plane(100)\n",
    "largest_group_pcd.estimate_covariances(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.05, max_nn=30))\n",
    "\n",
    "# Load your processed point cloud\n",
    "pcd = largest_group_pcd\n",
    "# Aggregate covariances\n",
    "aggregated_covariances = aggregate_covariances(pcd)\n",
    "\n",
    "# Compute eigenvalues and eigenvectors from aggregated covariances\n",
    "eigenvalues, eigenvectors = compute_eigenvalues_and_vectors_from_aggregated_covariances(aggregated_covariances)\n",
    "\n",
    "# Detect bifurcation points\n",
    "bifurcation_indices = detect_bifurcation_points(eigenvalues, percentile=3)[0]\n",
    "\n",
    "# Visualize bifurcation points (setting them as red)\n",
    "colors = np.asarray(pcd.colors)\n",
    "colors[bifurcation_indices] = [1, 0, 0]  # Red\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize the point cloud with bifurcation points highlighted\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"cherry_1.pcd\")\n",
    "\n",
    "pcd.get_oriented_bounding_box()\n",
    "\n",
    "# make frame\n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.6, origin=[0, 0, 0])\n",
    "\n",
    "# visualize the point cloud\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd, mesh_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompute neighbors.[========================================] 100%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Precompute neighbors.[========================================] 100%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Precompute neighbors.[========================================] 100%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Precompute neighbors.[========================================] 100%\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed point cloud\n",
    "for i in range(1, 5):\n",
    "    pcd = o3d.io.read_point_cloud(f\"3d-forest-classic-data/tree_{i}.pcd\")\n",
    "\n",
    "\n",
    "    # DBSCAN clustering\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=0.1, min_points=5, print_progress=True))\n",
    "\n",
    "    # Visualize the clustering result\n",
    "    max_label = labels.max()\n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\n",
    "    colors[labels < 0] = 0.5  # Set noise to black\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "    o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pcd_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonground_cherry_1.pcd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m pcd \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_point_cloud(pcd_path)\n\u001b[1;32m      4\u001b[0m frame \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mTriangleMesh\u001b[38;5;241m.\u001b[39mcreate_coordinate_frame(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, origin\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# o3d.visualization.draw_geometries([pcd, frame])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'o3d' is not defined"
     ]
    }
   ],
   "source": [
    "pcd_path = 'nonground_cherry_1.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])\n",
    "\n",
    "# o3d.visualization.draw_geometries([pcd, frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "pcd_path = 'trunk_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Estimate the normals\n",
    "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Visualize the point cloud with the normal estimates\n",
    "o3d.visualization.draw_geometries([pcd], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.001\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "print(f\"alpha={alpha:.3f}\")\n",
    "mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha)\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([mesh], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rotation_matrix_from_axis_angle(axis, angle):\n",
    "    # Ensure the axis is a unit vector\n",
    "    axis = axis / np.linalg.norm(axis)\n",
    "    \n",
    "    # Create the skew-symmetric cross-product matrix of the axis\n",
    "    ux, uy, uz = axis\n",
    "    skew_sym_matrix = np.array([\n",
    "        [0, -uz, uy],\n",
    "        [uz, 0, -ux],\n",
    "        [-uy, ux, 0]\n",
    "    ])\n",
    "    \n",
    "    # Calculate the rotation matrix using Rodrigues' formula\n",
    "    cos_theta = np.cos(angle)\n",
    "    sin_theta = np.sin(angle)\n",
    "    rotation_matrix = cos_theta * np.eye(3) + sin_theta * skew_sym_matrix + (1 - cos_theta) * np.outer(axis, axis)\n",
    "    \n",
    "    return rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_tree(pcd_path, output_path, center_threshold, normalize_colors=True, remove_points=True, distance_threshold=1, ransac_n=3, num_iterations=1000, frame_size=0.5):\n",
    "    # load point cloud\n",
    "    pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "    # downsample the point cloud\n",
    "\n",
    "    if normalize_colors:\n",
    "        # Normalize the colors\n",
    "        pcd_colors = np.asarray(pcd.colors)\n",
    "        pcd_colors /= 255.0\n",
    "        pcd.colors = o3d.utility.Vector3dVector(pcd_colors)\n",
    "\n",
    "    # Assuming filtered_pcd is your point cloud after filtering\n",
    "    plane_model, inliers = pcd.segment_plane(distance_threshold=distance_threshold, ransac_n=ransac_n, num_iterations=num_iterations)\n",
    "    [a, b, c, d] = plane_model\n",
    "\n",
    "    for i in inliers:\n",
    "        pcd.colors[i] = [1, 0, 0] # Red color\n",
    "\n",
    "    # The ground plane normal vector\n",
    "    ground_normal = np.array([a, b, c])\n",
    "\n",
    "    # Normalize the ground normal vector\n",
    "    ground_normal_normalized = ground_normal / np.linalg.norm(ground_normal)\n",
    "\n",
    "    # Calculate the rotation needed\n",
    "    # Z-axis unit vector\n",
    "    z_axis = np.array([0, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "    # Axis of rotation (cross product between ground normal and z-axis)\n",
    "    rotation_axis = np.cross(z_axis, ground_normal_normalized)\n",
    "\n",
    "    # Angle between ground normal and z-axis\n",
    "    rotation_angle = np.arccos(np.clip(np.dot(z_axis, ground_normal_normalized), -1.0, 1.0))\n",
    "\n",
    "    # Create the rotation matrix\n",
    "    rotation_matrix = create_rotation_matrix_from_axis_angle(rotation_axis, rotation_angle)\n",
    "\n",
    "    # Apply the rotation to align the ground plane with the XY plane\n",
    "    rotated_points = np.dot(np.asarray(pcd.points), rotation_matrix)\n",
    "\n",
    "    # flip across xy plane\n",
    "    # rotated_points[:, 2] = -rotated_points[:, 2] \n",
    "\n",
    "    # Update the point cloud with the rotated points\n",
    "    rotated_pcd = o3d.geometry.PointCloud()\n",
    "    rotated_pcd.points = o3d.utility.Vector3dVector(rotated_points)\n",
    "    rotated_pcd_points = np.asarray(rotated_pcd.points)\n",
    "    rotated_pcd.colors = pcd.colors\n",
    "    rotated_pcd_colors = np.asarray(rotated_pcd.colors)\n",
    "\n",
    "    # Calculate the mean of the inlier points to translate the point cloud\n",
    "    inlier_points = np.asarray(rotated_pcd.select_by_index(inliers).points)\n",
    "\n",
    "\n",
    "    mean_z_of_inliers = np.mean(inlier_points, axis=0)[2]\n",
    "\n",
    "\n",
    "    # Translate the point cloud down by the mean z value of the inliers\n",
    "    translated_points = np.asarray(rotated_pcd.points) - np.array([0, 0, mean_z_of_inliers])\n",
    "    inlier_points[:, 2] -= mean_z_of_inliers\n",
    "\n",
    "\n",
    "    trunk_indices = np.where((translated_points[:, 2] < center_threshold) & (translated_points[:, 2] > np.max(inlier_points[:, 2])))\n",
    "\n",
    "    # if there are no trunk points, use the inliers\n",
    "    if len(trunk_indices[0]) == 0:\n",
    "        trunk_indices = inliers\n",
    "\n",
    "    # remove outliers from trunk points\n",
    "\n",
    "    # rotated_pcd_colors[trunk_indices] = [0, 1, 0]\n",
    "\n",
    "\n",
    "    mean_x_of_trunk = np.mean(rotated_pcd_points[trunk_indices], axis=0)[0]\n",
    "    mean_y_of_trunk = np.mean(rotated_pcd_points[trunk_indices], axis=0)[1]\n",
    "\n",
    "    translated_points[:, 0] -= mean_x_of_trunk\n",
    "    translated_points[:, 1] -= mean_y_of_trunk\n",
    "\n",
    "\n",
    "    rotated_pcd.colors = o3d.utility.Vector3dVector(rotated_pcd_colors)\n",
    "\n",
    "    # remove the inliers\n",
    "    translated_points = np.delete(translated_points, inliers, axis=0)\n",
    "    rotated_pcd_colors = np.delete(rotated_pcd_colors, inliers, axis=0)\n",
    "\n",
    "    trunk_indices = np.where((translated_points[:, 2] < center_threshold) & (translated_points[:, 2] > np.max(inlier_points[:, 2])))\n",
    "\n",
    "    if len(trunk_indices[0]) != 0:\n",
    "\n",
    "        # # remove the trunk points\n",
    "        translated_points = np.delete(translated_points, trunk_indices, axis=0)\n",
    "        rotated_pcd_colors = np.delete(rotated_pcd_colors, trunk_indices, axis=0)\n",
    "\n",
    "    \n",
    "    translated_pcd = o3d.geometry.PointCloud()\n",
    "    translated_pcd.points = o3d.utility.Vector3dVector(translated_points)\n",
    "\n",
    "    # Explicitly set colors for translated_pcd before visualization\n",
    "    translated_pcd.colors = o3d.utility.Vector3dVector(rotated_pcd_colors)\n",
    "\n",
    "    # Access the points from the translated and aligned point cloud\n",
    "    # translated_points_array = np.asarray(translated_pcd.points)\n",
    "    translated_colors_array = np.asarray(translated_pcd.colors)\n",
    "\n",
    "    # remove outliers left from the plane segmentation\n",
    "    clf = IsolationForest(contamination=0.01)\n",
    "    clf.fit(translated_points)\n",
    "    y_pred = clf.predict(translated_points)\n",
    "    outliers = np.where(y_pred == -1)\n",
    "    inliers = np.where(y_pred == 1)\n",
    "    translated_points_array = np.delete(translated_points, outliers, axis=0)\n",
    "    translated_colors_array = np.delete(translated_colors_array, outliers, axis=0)\n",
    "\n",
    "    final_pcd = o3d.geometry.PointCloud()\n",
    "    final_pcd.points = o3d.utility.Vector3dVector(translated_points_array)\n",
    "    final_pcd.colors = o3d.utility.Vector3dVector(translated_colors_array)\n",
    "\n",
    "\n",
    "    frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=frame_size, origin=[0, 0, 0])\n",
    "\n",
    "    # downsample the point cloud\n",
    "    # final_pcd = final_pcd.voxel_down_sample(voxel_size=0.1)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([final_pcd, frame])\n",
    "\n",
    "    # Save the translated and aligned point cloud\n",
    "    o3d.io.write_point_cloud(output_path, final_pcd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# pcd_path = 'trunk_points.pcd'\n",
    "# translated_pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "# translated_pcd = translated_pcd.voxel_down_sample(voxel_size=0.005)\n",
    "# translated_points = np.asarray(translated_pcd.points)\n",
    "# sorted_indices = np.argsort(translated_points[:, 2])\n",
    "# sorted_points = translated_points[sorted_indices]\n",
    "\n",
    "# z_threshold = np.percentile(sorted_points[:, 2], 10)\n",
    "# bottom_points = sorted_points[sorted_points[:, 2] <= z_threshold]\n",
    "\n",
    "# # Find the bottom point closest to the origin\n",
    "# distances_to_origin = np.linalg.norm(bottom_points, axis=1)\n",
    "# index_closest_to_origin = np.argmin(distances_to_origin)\n",
    "# starting_point = bottom_points[index_closest_to_origin]\n",
    "\n",
    "# # Initialize the chain and visited points\n",
    "# chain = [starting_point]\n",
    "# visited = {tuple(starting_point)}\n",
    "\n",
    "# # Define the search radii\n",
    "# x_radius, y_radius, z_radius = 0.01, 0.01, 0.1  # Adjust as necessary\n",
    "\n",
    "# # Iteratively extend the chain\n",
    "# current_point = starting_point\n",
    "# # i = 0\n",
    "# while True:\n",
    "#     nearest_point = find_nearest_unvisited_within_xyz_radius(current_point, translated_points, visited, x_radius, y_radius, z_radius)\n",
    "#     if nearest_point is None:\n",
    "#         nearest_point = find_nearest_unvisited_within_xyz_radius(current_point, translated_points, visited, x_radius * 3, y_radius * 3, z_radius * 3)\n",
    "#         if nearest_point is None:\n",
    "#             break\n",
    "#         # break  # No further unvisited points within the specified radii\n",
    "#     chain.append(nearest_point)\n",
    "#     visited.add(tuple(nearest_point))\n",
    "#     current_point = nearest_point\n",
    "#     # print(i)\n",
    "#     # i += 1\n",
    "\n",
    "# # Prepare for visualization\n",
    "# lines = [[i, i+1] for i in range(len(chain)-1)]\n",
    "# chain_points = np.array(chain)\n",
    "# line_set = o3d.geometry.LineSet(\n",
    "#     points=o3d.utility.Vector3dVector(chain_points),\n",
    "#     lines=o3d.utility.Vector2iVector(lines)\n",
    "# )\n",
    "# line_set.colors = o3d.utility.Vector3dVector([[1, 0, 0] for i in range(len(lines))])  # Red lines for connections\n",
    "\n",
    "# # Visualize the point cloud and the chain\n",
    "# o3d.visualization.draw_geometries([translated_pcd, line_set], window_name=\"Aligned Point Cloud with Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "align_tree('cherry_2.xyzrgb', 'cherry_2_aligned_tree.pcd', remove_points=False, center_threshold=2, normalize_colors=True, distance_threshold=5, ransac_n=3, num_iterations=1000, frame_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'translated_pcd' is your modified point cloud ready for processing\n",
    "translated_points = np.asarray(translated_pcd.points)\n",
    "colors = np.asarray(translated_pcd.colors)\n",
    "\n",
    "# Step 1: Filter bottom points. Here, let's use the lowest 10% of points based on z-value.\n",
    "z_values = translated_points[:, 2]\n",
    "z_threshold = np.percentile(z_values, 10)  # Adjust the percentile as needed\n",
    "bottom_indices = np.where(z_values <= z_threshold)[0]\n",
    "bottom_points = translated_points[bottom_indices]\n",
    "\n",
    "# Step 2: Find nearest neighbors. For simplicity, this example uses a brute-force approach.\n",
    "connections = []\n",
    "for i, point in enumerate(bottom_points):\n",
    "    distances = np.linalg.norm(translated_points - point, axis=1)\n",
    "    distances[bottom_indices[i]] = np.inf  # Ignore the point itself\n",
    "    nearest_index = np.argmin(distances)\n",
    "    connections.append([point, translated_points[nearest_index]])\n",
    "\n",
    "# Convert connections to line set for visualization\n",
    "lines = [[i, i + len(bottom_points)] for i in range(len(bottom_points))]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]  # Red lines\n",
    "line_set = o3d.geometry.LineSet()\n",
    "line_set.points = o3d.utility.Vector3dVector(np.vstack((bottom_points, translated_points[bottom_indices])))\n",
    "line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Step 4: Visualize\n",
    "o3d.visualization.draw_geometries([translated_pcd, line_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the point cloud\n",
    "pcd_path = 'granny.xyzrgb'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(pcd.colors) / 255.0)\n",
    "\n",
    "# Assuming filtered_pcd is your point cloud after filtering\n",
    "plane_model, inliers = pcd.segment_plane(distance_threshold=1, ransac_n=3, num_iterations=1000)\n",
    "[a, b, c, d] = plane_model\n",
    "\n",
    "# The ground plane normal vector\n",
    "ground_normal = np.array([a, b, c])\n",
    "\n",
    "# Normalize the ground normal vector\n",
    "ground_normal_normalized = ground_normal / np.linalg.norm(ground_normal)\n",
    "\n",
    "# Calculate the rotation needed\n",
    "# Z-axis unit vector\n",
    "z_axis = np.array([0, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Axis of rotation (cross product between ground normal and z-axis)\n",
    "rotation_axis = np.cross(z_axis, ground_normal_normalized)\n",
    "\n",
    "# Angle between ground normal and z-axis\n",
    "rotation_angle = np.arccos(np.clip(np.dot(z_axis, ground_normal_normalized), -1.0, 1.0))\n",
    "\n",
    "# Create the rotation matrix\n",
    "rotation_matrix = create_rotation_matrix_from_axis_angle(rotation_axis, rotation_angle)\n",
    "\n",
    "# Apply the rotation to align the ground plane with the XY plane\n",
    "rotated_points = np.dot(np.asarray(pcd.points), rotation_matrix)\n",
    "\n",
    "# Update the point cloud with the rotated points\n",
    "rotated_pcd = o3d.geometry.PointCloud()\n",
    "rotated_pcd.points = o3d.utility.Vector3dVector(rotated_points)\n",
    "rotated_pcd.colors = pcd.colors\n",
    "\n",
    "# Calculate the mean of the inlier points to translate the point cloud\n",
    "inlier_points = np.asarray(rotated_pcd.select_by_index(inliers).points)\n",
    "mean_z_of_inliers = np.mean(inlier_points, axis=0)[2]\n",
    "\n",
    "# Translate the point cloud down by the mean z value of the inliers\n",
    "translated_points = np.asarray(rotated_pcd.points) - np.array([0, 0, mean_z_of_inliers])\n",
    "translated_pcd = o3d.geometry.PointCloud()\n",
    "translated_pcd.points = o3d.utility.Vector3dVector(translated_points)\n",
    "# Explicitly set colors for translated_pcd before visualization\n",
    "translated_pcd.colors = o3d.utility.Vector3dVector(np.asarray(rotated_pcd.colors))\n",
    "# Define your Z threshold\n",
    "z_min = 3.5  # Example threshold, adjust as needed\n",
    "z_max = 60  # Example threshold, adjust as needed\n",
    "\n",
    "# Access the points from the translated and aligned point cloud\n",
    "translated_points_array = np.asarray(translated_pcd.points)\n",
    "\n",
    "# Find indices of points that are above the Z threshold\n",
    "above_threshold_indices = np.where((translated_points_array[:, 2] > z_min) & (translated_points_array[:, 2] < z_max))[0]\n",
    "\n",
    "# Select only the points that are above the threshold\n",
    "filtered_points = translated_points_array[above_threshold_indices]\n",
    "\n",
    "# Also filter the colors to match the filtered points\n",
    "filtered_colors = np.asarray(translated_pcd.colors)[above_threshold_indices]\n",
    "\n",
    "# Create a new point cloud for the filtered points\n",
    "filtered_pcd = o3d.geometry.PointCloud()\n",
    "filtered_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "filtered_pcd.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "# remove statistical outliers\n",
    "cl, ind = filtered_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=1.0)\n",
    "\n",
    "# Create a frame to visualize the filtered point cloud\n",
    "frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=40, origin=[0, 0, 0])\n",
    "\n",
    "# Visualization of the filtered point cloud\n",
    "o3d.visualization.draw_geometries([filtered_pcd, frame], window_name=\"Filtered Point Cloud\")\n",
    "\n",
    "# Optionally, save the filtered point cloud\n",
    "o3d.io.write_point_cloud('granny_filtered_pcd.pcd', filtered_pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the point cloud\n",
    "pcd_path = 'cherry_2.xyzrgb'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Convert the RGB to 0-1 scale\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(pcd.colors) / 255.0)\n",
    "\n",
    "# Visualization\n",
    "# o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# Thresholding points by Z value\n",
    "z_threshold = -125\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Use boolean indexing to filter out points below the threshold\n",
    "above_threshold_indices = points[:, 2] > z_threshold\n",
    "filtered_points = points[above_threshold_indices]\n",
    "filtered_colors = colors[above_threshold_indices]\n",
    "\n",
    "# Create a new point cloud for the filtered data\n",
    "filtered_pcd = o3d.geometry.PointCloud()\n",
    "filtered_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "filtered_pcd.colors = o3d.utility.Vector3dVector(filtered_colors)\n",
    "\n",
    "# remove outliers\n",
    "plane_model, inliers = filtered_pcd.segment_plane(distance_threshold=0.06, ransac_n=3, num_iterations=1000)\n",
    "filtered_pcd = filtered_pcd.select_by_index(inliers, invert=True)\n",
    "filtered_pcd, ind = filtered_pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=1)\n",
    "\n",
    "# Visualization of the filtered point cloud\n",
    "o3d.visualization.draw_geometries([filtered_pcd], window_name=\"Filtered Point Cloud\")\n",
    "\n",
    "# Optionally save the filtered point cloud\n",
    "# o3d.io.write_point_cloud('cherry2_filtered_pcd.pcd', filtered_pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -24.54646492   20.71881676 -106.47665405]\n",
      " [ -85.41661072    0.25073901  -81.34545135]\n",
      " [ 104.64865875  -50.51711273  -49.45478821]\n",
      " [ -51.49118805   18.435812    -21.74301147]\n",
      " [ 136.69444275  -66.10697174  -74.6097641 ]\n",
      " [ -64.09218597   33.89157867  -24.89015579]\n",
      " [ 113.45696259  -31.25985336  -46.72667313]\n",
      " [ -77.57778168  -13.39559078  -22.51787758]\n",
      " [  94.6908493   -65.46487427  -16.20495224]\n",
      " [ -50.74226761  -61.21253967   -6.466043  ]]\n",
      "[[0.40784314 0.40784314 0.31372549]\n",
      " [0.44313725 0.39215686 0.35686275]\n",
      " [0.45098039 0.43137255 0.43921569]\n",
      " [0.42745098 0.42352941 0.34901961]\n",
      " [0.41960784 0.40784314 0.39215686]\n",
      " [0.62745098 0.60784314 0.56862745]\n",
      " [0.4745098  0.45882353 0.45882353]\n",
      " [0.41960784 0.38039216 0.38431373]\n",
      " [0.52941176 0.52156863 0.50980392]\n",
      " [0.45490196 0.43137255 0.41568627]]\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# # Load the point cloud\n",
    "# pcd_path = 'cherry2_filtered_pcd.pcd'\n",
    "# pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# # downsample the point cloud\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.1)\n",
    "\n",
    "# points = np.asarray(downpcd.points)\n",
    "\n",
    "# rgb_values = np.asarray(downpcd.colors)\n",
    "\n",
    "# print(points[:10])\n",
    "# print(rgb_values[:10])\n",
    "# # Scale spatial coordinates (X, Y, Z) and RGB values separately\n",
    "# spatial_weight = 1  # Keep spatial weight as 1 for now\n",
    "# color_weight = 10  # Increase this to give more weight to RGB values\n",
    "\n",
    "\n",
    "# # Assuming 'points' is your Nx3 array of spatial coordinates\n",
    "# # and 'rgb_values' is your Nx3 array of RGB values\n",
    "# weighted_features = np.hstack((points * spatial_weight, rgb_values * color_weight))\n",
    "\n",
    "# # Scale features to treat spatial and color dimensions equally\n",
    "# scaler = StandardScaler()\n",
    "# scaled_features = scaler.fit_transform(weighted_features)\n",
    "\n",
    "# # Apply DBSCAN on scaled features\n",
    "# dbscan = DBSCAN(eps=0.15, min_samples=10, algorithm='auto')  # Adjust eps and min_samples as needed\n",
    "# labels = dbscan.fit_predict(scaled_features)\n",
    "\n",
    "# # Assume 'points' and 'labels' are already defined from your DBSCAN clustering\n",
    "\n",
    "# # Generate a color map, one color per cluster\n",
    "# unique_labels = np.unique(labels)\n",
    "# colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))[:, :3]  # Exclude alpha channel\n",
    "\n",
    "# # Assign colors to each point based on its cluster label\n",
    "# point_colors = np.array([colors[label] if label != -1 else [0, 0, 0] for label in labels])\n",
    "\n",
    "# # Create a new Open3D point cloud\n",
    "# colored_pcd = o3d.geometry.PointCloud()\n",
    "# colored_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "# colored_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# # Visualization\n",
    "# o3d.visualization.draw_geometries([colored_pcd], window_name=\"Colored Point Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "average color = [0.46986817 0.46475677 0.38066137], standard deviation = [0.01019852 0.0096533  0.00886173]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 3\n",
    "\n",
    "# ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "\n",
    "# # visualization\n",
    "# # o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# # Load the point cloud data\n",
    "# pcd = o3d.io.read_point_cloud('cherry_1.pcd')\n",
    "# # downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# Load the point cloud\n",
    "pcd_path = 'cherry2_filtered_pcd.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# downsample the point cloud\n",
    "# pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "\n",
    "# # remove outliers\n",
    "# pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=0.5)\n",
    "\n",
    "\n",
    "# visualization\n",
    "# o3d.visualization.draw_geometries([nonground_pcd])\n",
    "\n",
    "# Save the non-ground point cloud for further processing\n",
    "# o3d.io.write_point_cloud(\"nonground_cherry_1.pcd\", nonground_pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjust brightness of the point cloud\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-3)\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    return np.clip(adjusted_colors, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "\n",
    "# Calculate target brightness\n",
    "target_brightness = np.mean(np.mean(np.asarray(pcd.colors), axis=1))\n",
    "\n",
    "# Adjust brightness\n",
    "adjusted_colors = adjust_brightness(np.asarray(pcd.colors), target_brightness)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_classes, random_state=42).fit(adjusted_colors)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Determine the greenest cluster\n",
    "green_label = np.argmax([np.mean(adjusted_colors[labels == i], axis=0)[1] for i in range(n_classes)])\n",
    "\n",
    "# Set non-green points to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label != green_label:\n",
    "        adjusted_colors[i] = [0, 0, 0]\n",
    "\n",
    "# Update point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud 1\")\n",
    "\n",
    "# Apply a slight outlier removal on the green points\n",
    "# Extract green points and their colors for outlier analysis\n",
    "green_points = np.asarray(pcd.points)[labels == green_label]\n",
    "green_colors = adjusted_colors[labels == green_label]\n",
    "\n",
    "# Use IsolationForest for outlier detection to slightly remove browner colors\n",
    "iso_forest = IsolationForest(contamination=0.31)  # Adjust this to control the degree of outlier removal\n",
    "outliers = iso_forest.fit_predict(green_colors)\n",
    "\n",
    "\n",
    "\n",
    "# # Update colors to remove slight outliers (set them to black)\n",
    "for i, outlier in enumerate(outliers):\n",
    "    if outlier == -1:\n",
    "        green_colors[i] = [0, 0, 0]  # Set outlier color to black\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "green_points = green_points[outliers != -1]\n",
    "green_colors = green_colors[outliers != -1]\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(green_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(green_colors)\n",
    "        \n",
    "\n",
    "# Update the original point cloud with the new colors\n",
    "adjusted_colors = np.asarray(pcd.colors)\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize and save the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud\")\n",
    "o3d.io.write_point_cloud('cherry2_processed_pcd.pcd', pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(np.any(adjusted_colors != [0, 0, 0], axis=1))[0]\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters with original color: 1260\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standardize the points\n",
    "# scaler = StandardScaler()\n",
    "# original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=7)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "average color = [0.47976684 0.52175942 0.37214818], standard deviation = [0.0088597 0.0105764 0.0104489]\n",
      "Number of clusters with original color: 1316\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "n_classes = 3\n",
    "\n",
    "# ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "\n",
    "# # visualization\n",
    "# # o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# # Load the point cloud data\n",
    "# pcd = o3d.io.read_point_cloud('cherry_1.pcd')\n",
    "# # downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# Load the point cloud\n",
    "pcd_path = 'granny_filtered_pcd.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# downsample the point cloud\n",
    "# pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "\n",
    "# # remove outliers\n",
    "# pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=0.5)\n",
    "\n",
    "\n",
    "# visualization\n",
    "# o3d.visualization.draw_geometries([nonground_pcd])\n",
    "\n",
    "# Save the non-ground point cloud for further processing\n",
    "# o3d.io.write_point_cloud(\"nonground_cherry_1.pcd\", nonground_pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjust brightness of the point cloud\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-3)\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    return np.clip(adjusted_colors, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "\n",
    "# Calculate target brightness\n",
    "target_brightness = np.mean(np.mean(np.asarray(pcd.colors), axis=1))\n",
    "\n",
    "# Adjust brightness\n",
    "adjusted_colors = adjust_brightness(np.asarray(pcd.colors), target_brightness)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_classes, random_state=42).fit(adjusted_colors)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Determine the greenest cluster\n",
    "green_label = np.argmax([np.mean(adjusted_colors[labels == i], axis=0)[1] for i in range(n_classes)])\n",
    "\n",
    "# Set non-green points to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label != green_label:\n",
    "        adjusted_colors[i] = [0, 0, 0]\n",
    "\n",
    "# Update point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud 1\")\n",
    "\n",
    "# Apply a slight outlier removal on the green points\n",
    "# Extract green points and their colors for outlier analysis\n",
    "green_points = np.asarray(pcd.points)[labels == green_label]\n",
    "green_colors = adjusted_colors[labels == green_label]\n",
    "\n",
    "# Use IsolationForest for outlier detection to slightly remove browner colors\n",
    "iso_forest = IsolationForest(contamination=0.31)  # Adjust this to control the degree of outlier removal\n",
    "outliers = iso_forest.fit_predict(green_colors)\n",
    "\n",
    "\n",
    "\n",
    "# # Update colors to remove slight outliers (set them to black)\n",
    "for i, outlier in enumerate(outliers):\n",
    "    if outlier == -1:\n",
    "        green_colors[i] = [0, 0, 0]  # Set outlier color to black\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "green_points = green_points[outliers != -1]\n",
    "green_colors = green_colors[outliers != -1]\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(green_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(green_colors)\n",
    "        \n",
    "\n",
    "# Update the original point cloud with the new colors\n",
    "adjusted_colors = np.asarray(pcd.colors)\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize and save the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud\")\n",
    "o3d.io.write_point_cloud('cherry2_processed_pcd.pcd', pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(np.any(adjusted_colors != [0, 0, 0], axis=1))[0]\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.03, min_samples=7)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "\n",
    "# ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "\n",
    "# # visualization\n",
    "# # o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# # Load the point cloud data\n",
    "# pcd = o3d.io.read_point_cloud('cherry_1.pcd')\n",
    "# # downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# Load the point cloud\n",
    "pcd_path = 'cherry2_filtered_pcd.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# downsample the point cloud\n",
    "# pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "\n",
    "# # remove outliers\n",
    "# pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=0.5)\n",
    "\n",
    "\n",
    "# visualization\n",
    "# o3d.visualization.draw_geometries([nonground_pcd])\n",
    "\n",
    "# Save the non-ground point cloud for further processing\n",
    "# o3d.io.write_point_cloud(\"nonground_cherry_1.pcd\", nonground_pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjust brightness of the point cloud\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-3)\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    return np.clip(adjusted_colors, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "\n",
    "# Calculate target brightness\n",
    "target_brightness = np.mean(np.mean(np.asarray(pcd.colors), axis=1))\n",
    "\n",
    "# Adjust brightness\n",
    "adjusted_colors = adjust_brightness(np.asarray(pcd.colors), target_brightness)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_classes, random_state=42).fit(adjusted_colors)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Determine the greenest cluster\n",
    "green_label = np.argmax([np.mean(adjusted_colors[labels == i], axis=0)[1] for i in range(n_classes)])\n",
    "\n",
    "# Set non-green points to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label != green_label:\n",
    "        adjusted_colors[i] = [0, 0, 0]\n",
    "\n",
    "# Update point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud 1\")\n",
    "\n",
    "# Apply a slight outlier removal on the green points\n",
    "# Extract green points and their colors for outlier analysis\n",
    "green_points = np.asarray(pcd.points)[labels == green_label]\n",
    "green_colors = adjusted_colors[labels == green_label]\n",
    "\n",
    "# Use IsolationForest for outlier detection to slightly remove browner colors\n",
    "iso_forest = IsolationForest(contamination=0.31)  # Adjust this to control the degree of outlier removal\n",
    "outliers = iso_forest.fit_predict(green_colors)\n",
    "\n",
    "\n",
    "\n",
    "# # Update colors to remove slight outliers (set them to black)\n",
    "for i, outlier in enumerate(outliers):\n",
    "    if outlier == -1:\n",
    "        green_colors[i] = [0, 0, 0]  # Set outlier color to black\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "green_points = green_points[outliers != -1]\n",
    "green_colors = green_colors[outliers != -1]\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(green_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(green_colors)\n",
    "        \n",
    "\n",
    "# Update the original point cloud with the new colors\n",
    "adjusted_colors = np.asarray(pcd.colors)\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize and save the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud\")\n",
    "o3d.io.write_point_cloud('cherry2_processed_pcd.pcd', pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(np.any(adjusted_colors != [0, 0, 0], axis=1))[0]\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.03, min_samples=7)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "average color = [nan nan nan], standard deviation = [nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Standardize the points\u001b[39;00m\n\u001b[1;32m    124\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m--> 125\u001b[0m original_color_points \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_color_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Apply DBSCAN to cluster these points\u001b[39;00m\n\u001b[1;32m    128\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Tweak these parameters as needed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:839\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:875\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    874\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:967\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 967\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    970\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    974\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "\n",
    "# ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "\n",
    "# # visualization\n",
    "# # o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# # Load the point cloud data\n",
    "# pcd = o3d.io.read_point_cloud('cherry_1.pcd')\n",
    "# # downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# Load the point cloud\n",
    "pcd = o3d.io.read_point_cloud(\"aligned_tree.pcd\")\n",
    "\n",
    "# pcd = o3d.io.read_point_cloud(\"nonground_cherry_1.pcd\")\n",
    "\n",
    "# downsample the point cloud\n",
    "# pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "\n",
    "# # remove outliers\n",
    "# pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=0.5)\n",
    "\n",
    "\n",
    "# visualization\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "# Save the non-ground point cloud for further processing\n",
    "# o3d.io.write_point_cloud(\"nonground_cherry_1.pcd\", nonground_pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjust brightness of the point cloud\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-3)\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    return np.clip(adjusted_colors, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "\n",
    "# Calculate target brightness\n",
    "target_brightness = np.mean(np.mean(np.asarray(pcd.colors), axis=1))\n",
    "\n",
    "# Adjust brightness\n",
    "adjusted_colors = adjust_brightness(np.asarray(pcd.colors), target_brightness)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=n_classes, random_state=42).fit(adjusted_colors)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Determine the greenest cluster\n",
    "green_label = np.argmax([np.mean(adjusted_colors[labels == i], axis=0)[1] for i in range(n_classes)])\n",
    "\n",
    "# Set non-green points to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label == green_label:\n",
    "        adjusted_colors[i] = [0, 0, 0]\n",
    "\n",
    "# Update point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud 1\")\n",
    "\n",
    "# Apply a slight outlier removal on the green points\n",
    "# Extract green points and their colors for outlier analysis\n",
    "green_points = np.asarray(pcd.points)[labels == green_label]\n",
    "green_colors = adjusted_colors[labels == green_label]\n",
    "\n",
    "# Use IsolationForest for outlier detection to slightly remove browner colors\n",
    "iso_forest = IsolationForest(contamination=0.4)  # Adjust this to control the degree of outlier removal\n",
    "outliers = iso_forest.fit_predict(green_colors)\n",
    "\n",
    "\n",
    "\n",
    "# # Update colors to remove slight outliers (set them to black)\n",
    "for i, outlier in enumerate(outliers):\n",
    "    if outlier == -1:\n",
    "        green_colors[i] = [0, 0, 0]  # Set outlier color to black\n",
    "\n",
    "\n",
    "# remove outliers\n",
    "green_points = green_points[outliers != -1]\n",
    "green_colors = green_colors[outliers != -1]\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(green_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(green_colors)\n",
    "        \n",
    "\n",
    "# Update the original point cloud with the new colors\n",
    "adjusted_colors = np.asarray(pcd.colors)\n",
    "pcd.colors = o3d.utility.Vector3dVector(adjusted_colors)\n",
    "\n",
    "# Visualize and save the processed point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Processed Point Cloud\")\n",
    "o3d.io.write_point_cloud('processed_pcd.pcd', pcd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(np.any(adjusted_colors != [0, 0, 0], axis=1))[0]\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = adjusted_colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.03, min_samples=10)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Read PCD failed: unable to open file: bloosom_points.pcd\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Write PCD failed: unable to generate header.\u001b[0;m\n",
      "Adjusted blossom points saved to adjusted_blossom_points.pcd\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The greenest color class is 0\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "KMeans segmented blossom points saved.\n",
      "average color = [0.60650577 0.62670773 0.42736661], standard deviation = [0.02244739 0.03536474 0.06326522]\n",
      "Number of clusters with original color: 885\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    # Calculate current brightness as the mean of RGB values\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    \n",
    "    # Calculate the factor needed to adjust each point to the target brightness\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-6)\n",
    "    \n",
    "    # Adjust colors\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    \n",
    "    # Ensure the adjusted colors are within valid range\n",
    "    adjusted_colors = np.clip(adjusted_colors, 0, 1)\n",
    "    \n",
    "    return adjusted_colors\n",
    "\n",
    "# Load the point cloud of blossom points\n",
    "pcd_path = 'bloosom_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors from the loaded point cloud\n",
    "all_colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Calculate the target brightness as the average brightness of all points\n",
    "target_brightness = np.mean(np.mean(all_colors, axis=1))\n",
    "\n",
    "# Adjust the brightness of all colors to the target brightness\n",
    "normalized_colors = adjust_brightness(all_colors, target_brightness)\n",
    "\n",
    "# Update the point cloud with normalized colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(normalized_colors)\n",
    "\n",
    "# Save the adjusted point cloud back to a file or visualize it\n",
    "adjusted_pcd_path = 'adjusted_blossom_points.pcd'\n",
    "o3d.io.write_point_cloud(adjusted_pcd_path, pcd)\n",
    "print(f\"Adjusted blossom points saved to {adjusted_pcd_path}\")\n",
    "\n",
    "# Visualize the adjusted point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Adjusted Brightness Blossoms\")\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the brightness-adjusted point cloud\n",
    "pcd_path = 'adjusted_blossom_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors and convert them to a suitable format for K-means\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Apply K-means clustering to segment the points based on color\n",
    "kmeans = KMeans(n_clusters=2, random_state=42).fit(colors)\n",
    "\n",
    "# Use labels to determine color assignment\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Initialize an array for the new colors\n",
    "new_colors = np.copy(colors)\n",
    "\n",
    "# Calculate the greenness of each color\n",
    "greenness = colors[:, 1] - (colors[:, 0] + colors[:, 2]) / 2\n",
    "\n",
    "# Calculate the average greenness for each color class\n",
    "average_greenness = [np.mean(greenness[labels == i]) for i in range(2)]\n",
    "\n",
    "# Find the color class with the highest average greenness\n",
    "greenest_class = np.argmax(average_greenness)\n",
    "\n",
    "print(f\"The greenest color class is {greenest_class}\")\n",
    "\n",
    "# Assign black color to one cluster and retain original color for the other\n",
    "# Assuming we want to turn the first cluster (label=0) to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label != greenest_class:\n",
    "        new_colors[i] = [0, 0, 0]  # Set color to black for one class\n",
    "\n",
    "# Update the point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(new_colors)\n",
    "\n",
    "# Visualize the point cloud with one class as black and the other in original color\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"KMeans Segmentation\")\n",
    "\n",
    "# Optionally, you can save this newly colored point cloud\n",
    "o3d.io.write_point_cloud('kmeans_segmented_blossom_points.pcd', pcd)\n",
    "print(\"KMeans segmented blossom points saved.\")\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(labels == greenest_class)[0]  # Assuming label=0 was assigned to black\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.025, min_samples=10)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    # Calculate current brightness as the mean of RGB values\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    \n",
    "    # Calculate the factor needed to adjust each point to the target brightness\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-6)\n",
    "    \n",
    "    # Adjust colors\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    \n",
    "    # Ensure the adjusted colors are within valid range\n",
    "    adjusted_colors = np.clip(adjusted_colors, 0, 1)\n",
    "    \n",
    "    return adjusted_colors\n",
    "\n",
    "# Load the point cloud of blossom points\n",
    "pcd_path = 'nonground_cherry_1.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors from the loaded point cloud\n",
    "all_colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Calculate the target brightness as the average brightness of all points\n",
    "target_brightness = np.mean(np.mean(all_colors, axis=1))\n",
    "\n",
    "# Adjust the brightness of all colors to the target brightness\n",
    "normalized_colors = adjust_brightness(all_colors, target_brightness)\n",
    "\n",
    "# Update the point cloud with normalized colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(normalized_colors)\n",
    "\n",
    "# Save the adjusted point cloud back to a file or visualize it\n",
    "adjusted_pcd_path = 'adjusted_blossom_points.pcd'\n",
    "o3d.io.write_point_cloud(adjusted_pcd_path, pcd)\n",
    "print(f\"Adjusted blossom points saved to {adjusted_pcd_path}\")\n",
    "\n",
    "# Visualize the adjusted point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Adjusted Brightness Blossoms\")\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the brightness-adjusted point cloud\n",
    "pcd_path = 'adjusted_blossom_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors and convert them to a suitable format for K-means\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Apply K-means clustering to segment the points based on color\n",
    "kmeans = KMeans(n_clusters=2, random_state=42).fit(colors)\n",
    "\n",
    "# Use labels to determine color assignment\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Initialize an array for the new colors\n",
    "new_colors = np.copy(colors)\n",
    "\n",
    "# Assign black color to one cluster and retain original color for the other\n",
    "# Assuming we want to turn the first cluster (label=0) to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label == 0:\n",
    "        new_colors[i] = [0, 0, 0]  # Set color to black for one class\n",
    "\n",
    "# Update the point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(new_colors)\n",
    "\n",
    "# Visualize the point cloud with one class as black and the other in original color\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"KMeans Segmentation\")\n",
    "\n",
    "# Optionally, you can save this newly colored point cloud\n",
    "o3d.io.write_point_cloud('kmeans_segmented_blossom_points.pcd', pcd)\n",
    "print(\"KMeans segmented blossom points saved.\")\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(labels != 0)[0]  # Assuming label=0 was assigned to black\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.025, min_samples=10)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -21.52998924 -100.98542023  -83.90379333]\n",
      " [ -51.49118805   18.435812    -21.74301147]\n",
      " [ 136.69444275  -66.10697174  -74.6097641 ]\n",
      " [-104.28185272  -20.62865448  -53.39678574]\n",
      " [ -78.24438477  -10.88687229  -88.60510254]\n",
      " [ -15.80795574 -141.78492737  -31.64421272]\n",
      " [ -40.37775421  -81.65332031  -84.59954071]\n",
      " [ -64.09218597   33.89157867  -24.89015579]\n",
      " [  94.08815765  -82.3712616   -25.92399788]\n",
      " [ -64.60190582   38.06379318  -96.91270447]]\n",
      "[[0.4        0.4        0.3254902 ]\n",
      " [0.42745098 0.42352941 0.34901961]\n",
      " [0.41960784 0.40784314 0.39215686]\n",
      " [0.52941176 0.50588235 0.43921569]\n",
      " [0.36470588 0.35294118 0.34117647]\n",
      " [0.42352941 0.4        0.36470588]\n",
      " [0.48235294 0.43921569 0.41176471]\n",
      " [0.62745098 0.60784314 0.56862745]\n",
      " [0.5254902  0.52156863 0.55686275]\n",
      " [0.40392157 0.38823529 0.36078431]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Apply DBSCAN on scaled features\u001b[39;00m\n\u001b[1;32m     43\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.22\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Adjust eps and min_samples as needed\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mdbscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Assume 'points' and 'labels' are already defined from your DBSCAN clustering\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Generate a color map, one color per cluster\u001b[39;00m\n\u001b[1;32m     49\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(labels)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_dbscan.py:454\u001b[0m, in \u001b[0;36mDBSCAN.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    430\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute clusters from a data or distance matrix and predict labels.\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        Cluster labels. Noisy samples are given the label -1.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_dbscan.py:402\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    400\u001b[0m neighbors_model\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# This has worst case O(n^2) memory complexity\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m neighborhoods \u001b[38;5;241m=\u001b[39m \u001b[43mneighbors_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     n_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m neighborhoods])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/neighbors/_base.py:1235\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m   1233\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m   1234\u001b[0m delayed_query \u001b[38;5;241m=\u001b[39m delayed(_tree_query_radius_parallel_helper)\n\u001b[0;32m-> 1235\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_results\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[1;32m   1242\u001b[0m     neigh_ind, neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mchunked_results))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/neighbors/_base.py:1013\u001b[0m, in \u001b[0;36m_tree_query_radius_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_radius_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in RadiusNeighborsMixin.radius_neighbors.\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query_radius is not directly picklable by\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m    cloudpickle under PyPy.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_radius\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# # Load the point cloud data\n",
    "# pcd = o3d.io.read_point_cloud('cherry_1.pcd')\n",
    "# # downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "\n",
    "# # Perform plane segmentation to separate ground\n",
    "# plane_model, inliers = pcd.segment_plane(distance_threshold=0.06,\n",
    "#                                              ransac_n=3,\n",
    "#                                              num_iterations=1000)\n",
    "\n",
    "# # Extract inliers and outliers\n",
    "# ground = pcd.select_by_index(inliers)\n",
    "# nonground_pcd = pcd.select_by_index(inliers, invert=True)\n",
    "\n",
    "# # Save the non-ground point cloud for further processing\n",
    "# o3d.io.write_point_cloud(\"nonground_cherry_1.pcd\", nonground_pcd)\n",
    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "pcd = o3d.io.read_point_cloud('cherry2_filtered_pcd.pcd')\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "points = np.asarray(downpcd.points)\n",
    "\n",
    "rgb_values = np.asarray(downpcd.colors)\n",
    "\n",
    "print(points[:10])\n",
    "print(rgb_values[:10])\n",
    "# Scale spatial coordinates (X, Y, Z) and RGB values separately\n",
    "spatial_weight = 1  # Keep spatial weight as 1 for now\n",
    "color_weight = 10  # Increase this to give more weight to RGB values\n",
    "spherical_variance_threshold = 1\n",
    "color_threshold = 1\n",
    "# continuity_threshold = 0.5\n",
    "\n",
    "\n",
    "# Assuming 'points' is your Nx3 array of spatial coordinates\n",
    "# and 'rgb_values' is your Nx3 array of RGB values\n",
    "weighted_features = np.hstack((points * spatial_weight, rgb_values * color_weight))\n",
    "\n",
    "# Scale features to treat spatial and color dimensions equally\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(weighted_features)\n",
    "\n",
    "# Apply DBSCAN on scaled features\n",
    "dbscan = DBSCAN(eps=0.22, min_samples=10, algorithm='auto')  # Adjust eps and min_samples as needed\n",
    "labels = dbscan.fit_predict(scaled_features)\n",
    "\n",
    "# Assume 'points' and 'labels' are already defined from your DBSCAN clustering\n",
    "\n",
    "# Generate a color map, one color per cluster\n",
    "unique_labels = np.unique(labels)\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))[:, :3]  # Exclude alpha channel\n",
    "\n",
    "# Assign colors to each point based on its cluster label\n",
    "point_colors = np.array([colors[label] if label != -1 else [0, 0, 0] for label in labels])\n",
    "\n",
    "# Create a new Open3D point cloud\n",
    "colored_pcd = o3d.geometry.PointCloud()\n",
    "colored_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "colored_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# # Visualize the colored point cloud\n",
    "# o3d.visualization.draw_geometries([colored_pcd], window_name='DBSCAN Clustering', width=3000, height=2000)\n",
    "\n",
    "\n",
    "def is_spherical(cluster_points):\n",
    "    centroid = np.mean(cluster_points, axis=0)\n",
    "    distances = np.linalg.norm(cluster_points - centroid, axis=1)\n",
    "    variance = np.var(distances)\n",
    "    return variance < spherical_variance_threshold\n",
    "\n",
    "def is_colorful(cluster_colors):\n",
    "    # Calculate the standard deviation across the RGB values of the cluster\n",
    "    color_std = np.std(cluster_colors, axis=0)\n",
    "    return np.mean(color_std) > color_threshold\n",
    "\n",
    "# Function to check cluster continuity\n",
    "# def check_continuity(cluster_points):\n",
    "#     # Compute pairwise distances within the cluster\n",
    "#     pairwise_dist = pairwise_distances(cluster_points)\n",
    "#     # Check if all points have at least one neighbor within the continuity threshold\n",
    "#     return np.all(np.any(pairwise_dist < continuity_threshold, axis=1))\n",
    "\n",
    "# Classify clusters\n",
    "spherical_clusters = []\n",
    "colorful_clusters = []\n",
    "# Apply continuity check\n",
    "# continuous_clusters = []\n",
    "\n",
    "# for label in np.unique(labels):\n",
    "#     if label == -1:  # Ignore noise\n",
    "#         continue\n",
    "#     cluster_points = points[labels == label]\n",
    "#     if check_continuity(cluster_points):\n",
    "#         continuous_clusters.append(label)\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == -1:  # Ignore noise\n",
    "        continue\n",
    "    cluster_points = points[labels == label]\n",
    "\n",
    "    cluster_colors = rgb_values[labels == label] * 255  # Assuming rgb_values are [0, 1], scale back to [0, 255]\n",
    "    \n",
    "    # Check if the cluster is spherical\n",
    "    if is_spherical(cluster_points):\n",
    "        spherical_clusters.append(label)\n",
    "    \n",
    "    # Check if the cluster is colorful (non-grey)\n",
    "    if is_colorful(cluster_colors):\n",
    "        colorful_clusters.append(label)\n",
    "\n",
    "# Assume a cluster is a blossom if it is both spherical and colorful\n",
    "blossom_clusters = set(spherical_clusters)\n",
    "# Color the clusters: Red for blossoms, Grey for non-blossom\n",
    "\n",
    "\n",
    "# Original point cloud colors\n",
    "original_colors = np.asarray(downpcd.colors)\n",
    "\n",
    "# Initialize all points as red first (for non-blossoms)\n",
    "# point_colors = np.ones_like(original_colors) * original_colors\n",
    "# point_colors = np.ones_like(original_colors) * [1, 1, 1]\n",
    "point_colors = np.ones_like(original_colors) * [1, 0, 0]\n",
    "\n",
    "\n",
    "blossom_count = 0\n",
    "# Assign the original color to points that are part of the blossom clusters\n",
    "for i, label in enumerate(labels):\n",
    "    if label in blossom_clusters:\n",
    "        point_colors[i] = [0.5, 0.5, 0.5]\n",
    "        # point_colors[i] = original_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud with updated colors\n",
    "colored_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "colored_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the updated point cloud with blossoms in original color and the rest in grey\n",
    "o3d.visualization.draw_geometries([colored_pcd], window_name='Blossom Classification', width=3000, height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000223\n",
      "8342\n",
      "Estimated number of blossoms: 140\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "pcd = o3d.io.read_point_cloud('cherry_1.pcd')\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.004)\n",
    "\n",
    "points = np.asarray(pcd.points)\n",
    "\n",
    "rgb_values = np.asarray(pcd.colors)\n",
    "# Threshold for identifying green points\n",
    "# Adjust these thresholds to correctly capture the green color of the blossoms in your dataset\n",
    "green_threshold = 0.42  # Minimum green value to be considered green\n",
    "red_blue_threshold = 0.4  # Maximum value for red and blue to ensure the point is predominantly green\n",
    "\n",
    "# Identify green points\n",
    "is_green = (rgb_values[:, 1] > green_threshold) & (rgb_values[:, 0] < red_blue_threshold) & (rgb_values[:, 2] < red_blue_threshold)\n",
    "print(len(points))\n",
    "green_points = points[is_green]\n",
    "print(len(green_points))\n",
    "\n",
    "# Apply DBSCAN to green points to identify individual blossoms\n",
    "dbscan_green = DBSCAN(eps=0.01, min_samples=5)  # Adjust eps and min_samples based on your dataset\n",
    "green_labels = dbscan_green.fit_predict(green_points)\n",
    "\n",
    "# Count the number of blossoms as the number of unique clusters found, excluding noise (label = -1)\n",
    "num_blossoms = len(set(green_labels)) - (1 if -1 in green_labels else 0)\n",
    "print(\"Estimated number of blossoms:\", num_blossoms)\n",
    "\n",
    "# Generate a color map for the green clusters\n",
    "unique_green_labels = np.unique(green_labels)\n",
    "green_colors = plt.cm.spring(np.linspace(0, 1, len(unique_green_labels)))\n",
    "\n",
    "# Get the original colors of the green points\n",
    "original_green_colors = rgb_values[is_green]\n",
    "\n",
    "# Create and visualize a point cloud for green clusters\n",
    "green_pcd = o3d.geometry.PointCloud()\n",
    "green_pcd.points = o3d.utility.Vector3dVector(green_points)\n",
    "green_pcd.colors = o3d.utility.Vector3dVector(original_green_colors)\n",
    "\n",
    "o3d.visualization.draw_geometries([green_pcd], window_name='Green Blossoms', width=3000, height=2000)\n",
    "# # Assuming 'points' is your data and 'labels' are the labels obtained from DBSCAN\n",
    "# unique_labels = np.unique(labels)\n",
    "# colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "\n",
    "# # Load the point cloud data\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.004)\n",
    "# points = np.asarray(downpcd.points)\n",
    "\n",
    "# # Scale spatial coordinates only, given we're focusing on structure\n",
    "# scaler = StandardScaler()\n",
    "# scaled_points = scaler.fit_transform(points)\n",
    "\n",
    "# # Apply DBSCAN on scaled spatial features, adjusted for structure emphasis\n",
    "# dbscan = DBSCAN(eps=0.1, min_samples=50)  # Adjust eps and min_samples based on visual inspection\n",
    "# labels = dbscan.fit_predict(scaled_points)\n",
    "\n",
    "# # Filter clusters based on size to eliminate noise and focus on main structural parts\n",
    "# unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# # Assume clusters representing structure have more points than a threshold\n",
    "# structure_clusters = unique_labels[counts > 100]  # Adjust threshold based on data\n",
    "\n",
    "# # Create a mask for points belonging to the structural clusters\n",
    "# structure_mask = np.isin(labels, structure_clusters)\n",
    "\n",
    "# # Extract structure points\n",
    "# structure_points = points[structure_mask]\n",
    "\n",
    "# # Create a point cloud for visualization\n",
    "# structure_pcd = o3d.geometry.PointCloud()\n",
    "# structure_pcd.points = o3d.utility.Vector3dVector(structure_points)\n",
    "# # Visualize the structural skeleton\n",
    "# o3d.visualization.draw_geometries([structure_pcd], window_name=\"Tree Structure\", width=3000, height=2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# import open3d as o3d\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Load and downsample the point cloud\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "# points = np.asarray(downpcd.points)\n",
    "# rgb_values = np.asarray(downpcd.colors)\n",
    "\n",
    "# # Feature Engineering: Combine spatial and RGB color features\n",
    "# # Note: Color weights might be adjusted to emphasize the grey shade similarity\n",
    "# # features = np.hstack((points, rgb_values * 10))  # Adjust color weight as needed\n",
    "\n",
    "# # # Scale combined features\n",
    "# # scaler = StandardScaler()\n",
    "# # scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# # Apply Agglomerative Clustering\n",
    "# # The choice of 'distance_threshold' allows us to control the granularity of the clustering\n",
    "# agg_clust = AgglomerativeClustering(n_clusters=None, distance_threshold=0.5, linkage='ward')  # Adjust the threshold\n",
    "# labels = agg_clust.fit_predict(points)\n",
    "\n",
    "# # # Identify significant clusters (with more than a threshold number of points)\n",
    "# # unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "# # significant_clusters = unique_labels[counts > 10]  # Threshold for significant clusters, adjust as needed\n",
    "\n",
    "# # # Filter points belonging to significant clusters\n",
    "# # significant_mask = np.isin(labels, significant_clusters)\n",
    "# # significant_points = points[significant_mask]\n",
    "# # significant_colors = rgb_values[significant_mask]  # For visual verification\n",
    "\n",
    "# # # Create a point cloud for the significant clusters\n",
    "# # significant_pcd = o3d.geometry.PointCloud()\n",
    "# # significant_pcd.points = o3d.utility.Vector3dVector(significant_points)\n",
    "# # significant_pcd.colors = o3d.utility.Vector3dVector(significant_colors)  # Use original colors for visualization\n",
    "\n",
    "# # # Visualize the filtered structural components\n",
    "# # o3d.visualization.draw_geometries([significant_pcd], window_name=\"Significant Tree Structure\", width=3000, height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import open3d as o3d\n",
    "\n",
    "# # Load and prepare the point cloud\n",
    "# pcd = o3d.io.read_point_cloud('nonground_cherry_1.pcd')\n",
    "# downpcd = pcd.voxel_down_sample(voxel_size=0.004)\n",
    "# points = np.asarray(downpcd.points)\n",
    "# rgb_values = np.asarray(downpcd.colors)\n",
    "\n",
    "# # Combine spatial and color features with weighting\n",
    "# features = np.hstack((points, rgb_values * 5))  # Adjust the weight for color features as needed\n",
    "\n",
    "# # Scale the combined features\n",
    "# scaler = StandardScaler()\n",
    "# scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# # Initialize and fit the Gaussian Mixture Model\n",
    "# # Adjust 'n_components' based on the expected segmentation of the tree and its surroundings\n",
    "# gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=0)\n",
    "# gmm_labels = gmm.fit_predict(scaled_features)\n",
    "\n",
    "# # Generate a color map for the GMM labels\n",
    "# unique_labels = np.unique(gmm_labels)\n",
    "# colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "# # Assign colors to each point based on its GMM label\n",
    "# gmm_point_colors = np.array([colors[label][:3] for label in gmm_labels])  # Exclude alpha channel\n",
    "\n",
    "# # Create a new Open3D point cloud for the GMM result\n",
    "# gmm_colored_pcd = o3d.geometry.PointCloud()\n",
    "# gmm_colored_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "# gmm_colored_pcd.colors = o3d.utility.Vector3dVector(gmm_point_colors)\n",
    "\n",
    "# # Visualize the GMM-segmented point cloud\n",
    "# o3d.visualization.draw_geometries([gmm_colored_pcd], window_name='GMM Segmentation', width=3000, height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blossom points saved to trunk_points.pcd\n",
      "Estimated number of blossoms: 0\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import json\n",
    "# # Load the point cloud\n",
    "# pcd_path = 'cherry_1.pcd'  # Adjust path if necessary\n",
    "# pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "# # pcd = pcd.voxel_down_sample(voxel_size=0.004)\n",
    "# points = np.asarray(pcd.points)\n",
    "# rgb_values = np.asarray(pcd.colors)\n",
    "\n",
    "# # Define a mapping from category_id to color (normalized to [0, 1] range)\n",
    "# category_to_color = {\n",
    "#     1: [0, 113/255, 188/255],  # Noise\n",
    "#     2: [216/255, 82/255, 24/255],  # Trunk\n",
    "#     3: [236/255, 176/255, 31/255],  # Branch\n",
    "#     4: [125/255, 46/255, 141/255],  # Leaf\n",
    "#     5: [118/255, 171/255, 47/255],  # Blossom\n",
    "#     6: [161/255, 19/255, 46/255]   # Ground\n",
    "# }\n",
    "\n",
    "# # load blossoms-v0.5.json\n",
    "# with open('blossoms-v0.5.json') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "\n",
    "# point_annotations = data['dataset']['samples'][0]['labels']['ground-truth']['attributes']['point_annotations']\n",
    "\n",
    "# # Convert point annotations to a NumPy array for efficient processing\n",
    "# point_annotations_np = np.array(point_annotations)\n",
    "\n",
    "# # Filter to get the indices of points labeled as blossoms (label 4)\n",
    "# blossom_indices = np.where(point_annotations_np == 1)[0]\n",
    "\n",
    "# # Select the points and colors for blossoms\n",
    "# blossom_points = np.asarray(pcd.points)[blossom_indices]\n",
    "# blossom_colors = np.asarray(pcd.colors)[blossom_indices]\n",
    "\n",
    "# # Create a new point cloud for the blossom points\n",
    "# # blossom_pcd = o3d.geometry.PointCloud()\n",
    "# # blossom_pcd.points = o3d.utility.Vector3dVector(blossom_points)\n",
    "# # blossom_pcd.colors = o3d.utility.Vector3dVector(blossom_colors)\n",
    "\n",
    "# # # Save the blossom point cloud to a new PCD file\n",
    "# # blossom_pcd_path = 'trunk_points.pcd'\n",
    "# # o3d.io.write_point_cloud(blossom_pcd_path, blossom_pcd)\n",
    "\n",
    "# # print(f\"Blossom points saved to {blossom_pcd_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaled_blossom_points = scaler.fit_transform(blossom_points)\n",
    "\n",
    "\n",
    "# # Ensure there are blossom points before applying DBSCAN\n",
    "# if len(blossom_points) > 0:\n",
    "#     dbscan_blossoms = DBSCAN(eps=0.015, min_samples=25, n_jobs=-1, leaf_size=1)\n",
    "#     blossom_labels = dbscan_blossoms.fit_predict(scaled_blossom_points)\n",
    "\n",
    "#     # Count the number of distinct blossom clusters\n",
    "#     num_blossoms = len(set(blossom_labels)) - (1 if -1 in blossom_labels else 0)\n",
    "#     print(\"Estimated number of blossoms:\", num_blossoms)\n",
    "\n",
    "#     # For visualization, you may assign colors based on the clustering result\n",
    "#     # Ensure blossom_colors is updated if you wish to use it for visualization\n",
    "# else:\n",
    "#     print(\"No blossom points were found.\")\n",
    "\n",
    "\n",
    "# # Prepare a color palette for clusters\n",
    "# num_clusters = len(set(blossom_labels)) - (1 if -1 in blossom_labels else 0)\n",
    "# cluster_colors = plt.cm.get_cmap('viridis', num_clusters)\n",
    "\n",
    "# # Initialize an array to hold colors for all points in the original point cloud\n",
    "# all_point_colors = np.array([category_to_color[5] for _ in range(len(points))])  # Start with all points as blossom color\n",
    "\n",
    "# # Assign colors to blossom points based on DBSCAN cluster labels\n",
    "# for i, cluster_label in enumerate(blossom_labels):\n",
    "#     if cluster_label == -1:  # Noise\n",
    "#         color = [0, 0, 0]  # Black for noise\n",
    "#     else:\n",
    "#         color = cluster_colors(cluster_label)[:3]  # Exclude alpha channel from RGBA\n",
    "#     all_point_colors[blossom_indices[i]] = color  # Update color for this point\n",
    "\n",
    "# # Update the colors of the original point cloud\n",
    "# pcd.colors = o3d.utility.Vector3dVector(all_point_colors)\n",
    "\n",
    "# # Now select indices where the label is 4 (leaves)\n",
    "# blossom_indices = np.where(point_annotations_np == 1)[0]\n",
    "\n",
    "\n",
    "# # Select the leaf points using these indices\n",
    "# blossom_points = points[blossom_indices]\n",
    "# blossom_colors = rgb_values[blossom_indices]  # If you want to use original colors for visualization\n",
    "\n",
    "# # optional visualization of the blossom points\n",
    "# # # Create a new point cloud for the blossom points with DBSCAN colors\n",
    "# # dbscan_colored_pcd = o3d.geometry.PointCloud()\n",
    "# # dbscan_colored_pcd.points = o3d.utility.Vector3dVector(blossom_points)\n",
    "# # dbscan_colored_pcd.colors = o3d.utility.Vector3dVector(blossom_colors)\n",
    "\n",
    "# # # Visualize the DBSCAN clustered blossom points\n",
    "# # o3d.visualization.draw_geometries([dbscan_colored_pcd], window_name='DBSCAN Blossom Clustering', width=3000, height=2000)\n",
    "\n",
    "# # Prepare a color palette for clusters, including a color for noise (-1 labels)\n",
    "# unique_labels = np.unique(blossom_labels)\n",
    "# num_unique_labels = len(unique_labels[unique_labels != -1])\n",
    "# cluster_colors = plt.cm.get_cmap('viridis', num_unique_labels)\n",
    "\n",
    "# # Map DBSCAN labels to colors\n",
    "# label_to_color = {\n",
    "#     label: cluster_colors(i)[:3] for i, label in enumerate(unique_labels)\n",
    "# }\n",
    "\n",
    "# # For noise points, you might want to use a distinct color, like black\n",
    "# label_to_color[-1] = [0, 0, 0]\n",
    "\n",
    "# # Assign colors to blossom points based on DBSCAN cluster labels\n",
    "# dbscan_colors = np.array([label_to_color[label] for label in blossom_labels])\n",
    "\n",
    "# # Create a new point cloud for the blossom points with DBSCAN colors\n",
    "# dbscan_colored_pcd = o3d.geometry.PointCloud()\n",
    "# dbscan_colored_pcd.points = o3d.utility.Vector3dVector(blossom_points)\n",
    "# dbscan_colored_pcd.colors = o3d.utility.Vector3dVector(dbscan_colors)\n",
    "\n",
    "# # Visualize the DBSCAN clustered blossom points\n",
    "# o3d.visualization.draw_geometries([dbscan_colored_pcd], window_name='DBSCAN Blossom Clustering', width=3000, height=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import open3d as o3d\n",
    "# import json\n",
    "\n",
    "# # Function to adjust brightness\n",
    "# def adjust_brightness(colors, target_brightness):\n",
    "#     # Calculate current brightness as the mean of RGB values\n",
    "#     current_brightness = np.mean(colors, axis=1)\n",
    "    \n",
    "#     # Calculate the factor needed to adjust each point to the target brightness\n",
    "#     brightness_factor = target_brightness / (current_brightness + 1e-6)\n",
    "    \n",
    "#     # Adjust colors\n",
    "#     adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    \n",
    "#     # Ensure the adjusted colors are within valid range\n",
    "#     adjusted_colors = np.clip(adjusted_colors, 0, 1)\n",
    "    \n",
    "#     return adjusted_colors\n",
    "\n",
    "# # Load the point cloud\n",
    "# pcd_path = 'blossom_points.pcd'  # Adjust the path to your point cloud file\n",
    "# pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# # Extract all points and colors\n",
    "# all_points = np.asarray(pcd.points)\n",
    "# all_colors = np.asarray(pcd.colors)\n",
    "\n",
    "# # Target brightness calculation and adjustment should only be applied to blossom points\n",
    "# blossom_colors = all_colors[blossom_indices]\n",
    "# target_brightness = np.mean(np.mean(blossom_colors, axis=1))\n",
    "# normalized_colors = adjust_brightness(blossom_colors, target_brightness)\n",
    "\n",
    "# # Create a full color array and update only the blossom indices with normalized colors\n",
    "# full_normalized_colors = all_colors.copy()\n",
    "# full_normalized_colors[blossom_indices] = normalized_colors\n",
    "\n",
    "# # Update the point cloud with the full normalized colors\n",
    "# pcd.colors = o3d.utility.Vector3dVector(full_normalized_colors)\n",
    "\n",
    "# # Visualize the point cloud with brightness-normalized blossom colors\n",
    "# o3d.visualization.draw_geometries([pcd], window_name=\"Brightness Normalized Blossoms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted blossom points saved to adjusted_blossom_points.pcd\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "KMeans segmented blossom points saved.\n",
      "average color = [0.6105101  0.62712522 0.46248604], standard deviation = [0.0211496  0.03430516 0.04783854]\n",
      "Number of clusters with original color: 893\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import open3d as o3d\n",
    "\n",
    "# def adjust_brightness(colors, target_brightness):\n",
    "#     # Calculate current brightness as the mean of RGB values\n",
    "#     current_brightness = np.mean(colors, axis=1)\n",
    "    \n",
    "#     # Calculate the factor needed to adjust each point to the target brightness\n",
    "#     brightness_factor = target_brightness / (current_brightness + 1e-6)\n",
    "    \n",
    "#     # Adjust colors\n",
    "#     adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    \n",
    "#     # Ensure the adjusted colors are within valid range\n",
    "#     adjusted_colors = np.clip(adjusted_colors, 0, 1)\n",
    "    \n",
    "#     return adjusted_colors\n",
    "\n",
    "# # Load the point cloud of blossom points\n",
    "# pcd_path = 'blossom_points.pcd'\n",
    "# pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# # Extract colors from the loaded point cloud\n",
    "# all_colors = np.asarray(pcd.colors)\n",
    "\n",
    "# # Calculate the target brightness as the average brightness of all points\n",
    "# target_brightness = np.mean(np.mean(all_colors, axis=1))\n",
    "\n",
    "# # Adjust the brightness of all colors to the target brightness\n",
    "# normalized_colors = adjust_brightness(all_colors, target_brightness)\n",
    "\n",
    "# # Update the point cloud with normalized colors\n",
    "# pcd.colors = o3d.utility.Vector3dVector(normalized_colors)\n",
    "\n",
    "# # Save the adjusted point cloud back to a file or visualize it\n",
    "# adjusted_pcd_path = 'adjusted_blossom_points.pcd'\n",
    "# o3d.io.write_point_cloud(adjusted_pcd_path, pcd)\n",
    "# print(f\"Adjusted blossom points saved to {adjusted_pcd_path}\")\n",
    "\n",
    "# # Visualize the adjusted point cloud\n",
    "# o3d.visualization.draw_geometries([pcd], window_name=\"Adjusted Brightness Blossoms\")\n",
    "\n",
    "# import numpy as np\n",
    "# import open3d as o3d\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Load the brightness-adjusted point cloud\n",
    "# pcd_path = 'adjusted_blossom_points.pcd'\n",
    "# pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# # Extract colors and convert them to a suitable format for K-means\n",
    "# colors = np.asarray(pcd.colors)\n",
    "\n",
    "# # Apply K-means clustering to segment the points based on color\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42).fit(colors)\n",
    "\n",
    "# # Use labels to determine color assignment\n",
    "# labels = kmeans.labels_\n",
    "\n",
    "# # Initialize an array for the new colors\n",
    "# new_colors = np.copy(colors)\n",
    "\n",
    "# # Assign black color to one cluster and retain original color for the other\n",
    "# # Assuming we want to turn the first cluster (label=0) to black\n",
    "# for i, label in enumerate(labels):\n",
    "#     if label == 0:\n",
    "#         new_colors[i] = [0, 0, 0]  # Set color to black for one class\n",
    "\n",
    "# # Update the point cloud colors\n",
    "# pcd.colors = o3d.utility.Vector3dVector(new_colors)\n",
    "\n",
    "# # Visualize the point cloud with one class as black and the other in original color\n",
    "# o3d.visualization.draw_geometries([pcd], window_name=\"KMeans Segmentation\")\n",
    "\n",
    "# # Optionally, you can save this newly colored point cloud\n",
    "# o3d.io.write_point_cloud('kmeans_segmented_blossom_points.pcd', pcd)\n",
    "# print(\"KMeans segmented blossom points saved.\")\n",
    "\n",
    "# from sklearn.cluster import DBSCAN\n",
    "\n",
    "# # First, identify points that retained their original color (not turned black)\n",
    "# original_color_indices = np.where(labels != 0)[0]  # Assuming label=0 was assigned to black\n",
    "\n",
    "# # Extract the colors of these points\n",
    "# original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# # Calculate average color and standard deviation for these points\n",
    "# average_color = np.mean(original_color_colors, axis=0)\n",
    "# std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "# print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# # Extract the points and colors of these points\n",
    "# original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "# original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# # Standardize the points\n",
    "# scaler = StandardScaler()\n",
    "# original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# # Apply DBSCAN to cluster these points\n",
    "# dbscan = DBSCAN(eps=0.025, min_samples=10)  # Tweak these parameters as needed\n",
    "# dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# # Initialize variables to store analysis results\n",
    "# cluster_average_colors = []\n",
    "# cluster_std_dev_colors = []\n",
    "\n",
    "# # Analyze each cluster (excluding noise, labeled as -1)\n",
    "# for cluster_label in set(dbscan_labels):\n",
    "#     if cluster_label == -1:\n",
    "#         continue  # Skip noise\n",
    "#     cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "#     cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "#     # Calculate average color and standard deviation for the cluster\n",
    "#     average_color = np.mean(cluster_colors, axis=0)\n",
    "#     std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "#     cluster_average_colors.append(average_color)\n",
    "#     cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# # Print out the analysis results\n",
    "# num_clusters = len(cluster_average_colors)\n",
    "# print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# # for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "# #     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Generate a color map with a unique color for each cluster\n",
    "# color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# # Initialize an array to store the colors of the points\n",
    "# point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# # Assign each cluster a unique color\n",
    "# for cluster_label in set(dbscan_labels):\n",
    "#     if cluster_label == -1:\n",
    "#         continue  # Skip noise\n",
    "#     cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "#     point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# # Create a new Open3D point cloud for visualization\n",
    "# clustered_pcd = o3d.geometry.PointCloud()\n",
    "# clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "# clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# # Visualize the clustered point cloud\n",
    "# o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# # Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# # It may need adjustment based on the scale of your data and the desired granularity of clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted blossom points saved to adjusted_blossom_points.pcd\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The greenest color class is 2\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "KMeans segmented blossom points saved.\n",
      "average color = [0.56945113 0.59502062 0.39700013], standard deviation = [0.02066276 0.03098036 0.04174099]\n",
      "Number of clusters with original color: 715\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    # Calculate current brightness as the mean of RGB values\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    \n",
    "    # Calculate the factor needed to adjust each point to the target brightness\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-6)\n",
    "    \n",
    "    # Adjust colors\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    \n",
    "    # Ensure the adjusted colors are within valid range\n",
    "    adjusted_colors = np.clip(adjusted_colors, 0, 1)\n",
    "    \n",
    "    return adjusted_colors\n",
    "\n",
    "# Load the point cloud of blossom points\n",
    "pcd_path = 'nonground_cherry_1.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors from the loaded point cloud\n",
    "all_colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Calculate the target brightness as the average brightness of all points\n",
    "target_brightness = np.mean(np.mean(all_colors, axis=1))\n",
    "\n",
    "# Adjust the brightness of all colors to the target brightness\n",
    "normalized_colors = adjust_brightness(all_colors, target_brightness)\n",
    "\n",
    "# Update the point cloud with normalized colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(normalized_colors)\n",
    "\n",
    "# Save the adjusted point cloud back to a file or visualize it\n",
    "adjusted_pcd_path = 'adjusted_blossom_points.pcd'\n",
    "o3d.io.write_point_cloud(adjusted_pcd_path, pcd)\n",
    "print(f\"Adjusted blossom points saved to {adjusted_pcd_path}\")\n",
    "\n",
    "# Visualize the adjusted point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Adjusted Brightness Blossoms\")\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the brightness-adjusted point cloud\n",
    "pcd_path = 'adjusted_blossom_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors and convert them to a suitable format for K-means\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Apply K-means clustering to segment the points based on color\n",
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(colors)\n",
    "\n",
    "# Use labels to determine color assignment\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Initialize an array for the new colors\n",
    "new_colors = np.copy(colors)\n",
    "\n",
    "# Calculate the greenness of each color\n",
    "greenness = colors[:, 1] - (colors[:, 0] + colors[:, 2]) / 2\n",
    "\n",
    "# Calculate the average greenness for each color class\n",
    "average_greenness = [np.mean(greenness[labels == i]) for i in range(3)]\n",
    "\n",
    "# Find the color class with the highest average greenness\n",
    "greenest_class = np.argmax(average_greenness)\n",
    "\n",
    "print(f\"The greenest color class is {greenest_class}\")\n",
    "\n",
    "# Assign black color to one cluster and retain original color for the other\n",
    "# Assuming we want to turn the first cluster (label=0) to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label != greenest_class:\n",
    "        new_colors[i] = [0, 0, 0]  # Set color to black for one class\n",
    "\n",
    "# Update the point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(new_colors)\n",
    "\n",
    "# Visualize the point cloud with one class as black and the other in original color\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"KMeans Segmentation\")\n",
    "\n",
    "# Optionally, you can save this newly colored point cloud\n",
    "o3d.io.write_point_cloud('kmeans_segmented_blossom_points.pcd', pcd)\n",
    "print(\"KMeans segmented blossom points saved.\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(labels == greenest_class)[0]  # Assuming label=0 was assigned to black\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.03, min_samples=10)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted blossom points saved to adjusted_blossom_points.pcd\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "KMeans segmented blossom points saved.\n",
      "average color = [0.55708157 0.56546252 0.4389234 ], standard deviation = [0.02006236 0.03143084 0.04090002]\n",
      "Number of clusters with original color: 1349\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def adjust_brightness(colors, target_brightness):\n",
    "    # Calculate current brightness as the mean of RGB values\n",
    "    current_brightness = np.mean(colors, axis=1)\n",
    "    \n",
    "    # Calculate the factor needed to adjust each point to the target brightness\n",
    "    brightness_factor = target_brightness / (current_brightness + 1e-6)\n",
    "    \n",
    "    # Adjust colors\n",
    "    adjusted_colors = colors * brightness_factor[:, np.newaxis]\n",
    "    \n",
    "    # Ensure the adjusted colors are within valid range\n",
    "    adjusted_colors = np.clip(adjusted_colors, 0, 1)\n",
    "    \n",
    "    return adjusted_colors\n",
    "\n",
    "# Load the point cloud of blossom points\n",
    "pcd_path = 'bloosom_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors from the loaded point cloud\n",
    "all_colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Calculate the target brightness as the average brightness of all points\n",
    "target_brightness = np.mean(np.mean(all_colors, axis=1))\n",
    "\n",
    "# Adjust the brightness of all colors to the target brightness\n",
    "normalized_colors = adjust_brightness(all_colors, target_brightness)\n",
    "\n",
    "# Update the point cloud with normalized colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(normalized_colors)\n",
    "\n",
    "# Save the adjusted point cloud back to a file or visualize it\n",
    "adjusted_pcd_path = 'adjusted_blossom_points.pcd'\n",
    "o3d.io.write_point_cloud(adjusted_pcd_path, pcd)\n",
    "print(f\"Adjusted blossom points saved to {adjusted_pcd_path}\")\n",
    "\n",
    "# Visualize the adjusted point cloud\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"Adjusted Brightness Blossoms\")\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the brightness-adjusted point cloud\n",
    "pcd_path = 'adjusted_blossom_points.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Extract colors and convert them to a suitable format for K-means\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Apply K-means clustering to segment the points based on color\n",
    "kmeans = KMeans(n_clusters=2, random_state=42).fit(colors)\n",
    "\n",
    "# Use labels to determine color assignment\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Initialize an array for the new colors\n",
    "new_colors = np.copy(colors)\n",
    "\n",
    "# Assign black color to one cluster and retain original color for the other\n",
    "# Assuming we want to turn the first cluster (label=0) to black\n",
    "for i, label in enumerate(labels):\n",
    "    if label == 0:\n",
    "        new_colors[i] = [0, 0, 0]  # Set color to black for one class\n",
    "\n",
    "# Update the point cloud colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(new_colors)\n",
    "\n",
    "# Visualize the point cloud with one class as black and the other in original color\n",
    "o3d.visualization.draw_geometries([pcd], window_name=\"KMeans Segmentation\")\n",
    "\n",
    "# Optionally, you can save this newly colored point cloud\n",
    "o3d.io.write_point_cloud('kmeans_segmented_blossom_points.pcd', pcd)\n",
    "print(\"KMeans segmented blossom points saved.\")\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# First, identify points that retained their original color (not turned black)\n",
    "original_color_indices = np.where(labels != 0)[0]  # Assuming label=0 was assigned to black\n",
    "\n",
    "# Extract the colors of these points\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Calculate average color and standard deviation for these points\n",
    "average_color = np.mean(original_color_colors, axis=0)\n",
    "std_dev_color = np.std(original_color_colors, axis=0)\n",
    "\n",
    "print(f\"average color = {average_color}, standard deviation = {std_dev_color}\")\n",
    "\n",
    "# Extract the points and colors of these points\n",
    "original_color_points = np.asarray(pcd.points)[original_color_indices]\n",
    "original_color_colors = colors[original_color_indices]\n",
    "\n",
    "# Standardize the points\n",
    "scaler = StandardScaler()\n",
    "original_color_points = scaler.fit_transform(original_color_points)\n",
    "\n",
    "# Apply DBSCAN to cluster these points\n",
    "dbscan = DBSCAN(eps=0.025, min_samples=10)  # Tweak these parameters as needed\n",
    "dbscan_labels = dbscan.fit_predict(original_color_points)\n",
    "\n",
    "# Initialize variables to store analysis results\n",
    "cluster_average_colors = []\n",
    "cluster_std_dev_colors = []\n",
    "\n",
    "# Analyze each cluster (excluding noise, labeled as -1)\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    cluster_colors = original_color_colors[cluster_indices]\n",
    "    \n",
    "    # Calculate average color and standard deviation for the cluster\n",
    "    average_color = np.mean(cluster_colors, axis=0)\n",
    "    std_dev_color = np.std(cluster_colors, axis=0)\n",
    "    \n",
    "    cluster_average_colors.append(average_color)\n",
    "    cluster_std_dev_colors.append(std_dev_color)\n",
    "\n",
    "# Print out the analysis results\n",
    "num_clusters = len(cluster_average_colors)\n",
    "print(f\"Number of clusters with original color: {num_clusters}\")\n",
    "# for i, (avg_color, std_dev) in enumerate(zip(cluster_average_colors, cluster_std_dev_colors), start=1):\n",
    "#     print(f\"Cluster {i}: Average Color = {avg_color}, Standard Deviation = {std_dev}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a color map with a unique color for each cluster\n",
    "color_map = plt.cm.get_cmap('jet', len(set(dbscan_labels)))\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each cluster a unique color\n",
    "for cluster_label in set(dbscan_labels):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Skip noise\n",
    "    cluster_indices = np.where(dbscan_labels == cluster_label)[0]\n",
    "    point_colors[cluster_indices] = color_map(cluster_label)[:3]  # Slice to keep only RGB, ignore alpha\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "clustered_pcd = o3d.geometry.PointCloud()\n",
    "clustered_pcd.points = o3d.utility.Vector3dVector(original_color_points)\n",
    "clustered_pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualize the clustered point cloud\n",
    "o3d.visualization.draw_geometries([clustered_pcd], window_name=\"Clustered Point Cloud\")\n",
    "\n",
    "# Initialize an array to store the colors of the points\n",
    "original_point_colors = np.zeros((len(original_color_points), 3))\n",
    "\n",
    "# Assign each point its original color\n",
    "for i, label in enumerate(dbscan_labels):\n",
    "    if label != -1:  # Skip noise\n",
    "        original_point_colors[i] = original_color_colors[i]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "original_color_pcd = o3d.geometry.PointCloud()\n",
    "original_color_pcd.points = o3d.utility.Vector3dVector(original_color_points[dbscan_labels != -1])\n",
    "original_color_pcd.colors = o3d.utility.Vector3dVector(original_point_colors[dbscan_labels != -1])\n",
    "\n",
    "# Visualize the point cloud with original colors\n",
    "o3d.visualization.draw_geometries([original_color_pcd], window_name=\"Original Color Point Cloud\")\n",
    "\n",
    "# Note: The eps parameter in DBSCAN affects the size and number of clusters\n",
    "# It may need adjustment based on the scale of your data and the desired granularity of clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blossom_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(pcd\u001b[38;5;241m.\u001b[39mpoints)\n\u001b[1;32m      8\u001b[0m rgb_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(pcd\u001b[38;5;241m.\u001b[39mcolors) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m  \u001b[38;5;66;03m# Assuming rgb_values are normalized between 0 and 1\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m blossom_points \u001b[38;5;241m=\u001b[39m points[\u001b[43mblossom_indices\u001b[49m]\n\u001b[1;32m     10\u001b[0m blossom_colors \u001b[38;5;241m=\u001b[39m rgb_values[blossom_indices]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Step 1: Spatial clustering with DBSCAN\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blossom_indices' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pcd is your point cloud and blossom_indices identifies the blossom points\n",
    "points = np.asarray(pcd.points)\n",
    "rgb_values = np.asarray(pcd.colors) * 255  # Assuming rgb_values are normalized between 0 and 1\n",
    "blossom_points = points[blossom_indices]\n",
    "blossom_colors = rgb_values[blossom_indices]\n",
    "\n",
    "# Step 1: Spatial clustering with DBSCAN\n",
    "dbscan = DBSCAN(eps=0.1, min_samples=10)  # Adjust eps and min_samples as needed\n",
    "spatial_labels = dbscan.fit_predict(blossom_points)\n",
    "\n",
    "segmented_colors = np.zeros((len(blossom_points), 3))\n",
    "\n",
    "for spatial_label in np.unique(spatial_labels):\n",
    "    if spatial_label == -1:  # Skip noise points\n",
    "        continue\n",
    "    cluster_indices = np.where(spatial_labels == spatial_label)[0]\n",
    "    cluster_colors = blossom_colors[cluster_indices]\n",
    "\n",
    "    # Step 2: Color clustering within each spatial cluster using K-means\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42).fit(cluster_colors)\n",
    "    color_labels = kmeans.labels_\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    for i, label in enumerate(color_labels):\n",
    "        if label == color_labels[0]:\n",
    "            # Retain original color for points identified as green\n",
    "            segmented_colors[cluster_indices[i]] = blossom_colors[cluster_indices[i]]\n",
    "        else:\n",
    "            # Use black for other points\n",
    "            segmented_colors[cluster_indices[i]] = [0, 0, 0]\n",
    "\n",
    "# Create a new Open3D point cloud for visualization\n",
    "segmented_pcd = o3d.geometry.PointCloud()\n",
    "segmented_pcd.points = o3d.utility.Vector3dVector(blossom_points)\n",
    "segmented_pcd.colors = o3d.utility.Vector3dVector(segmented_colors / 255)  # Normalize colors to [0, 1] if necessary\n",
    "\n",
    "# Visualize the segmented point cloud\n",
    "o3d.visualization.draw_geometries([segmented_pcd], window_name=\"Segmented Blossom Clustering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "Cluster 0 mean color: [0.25847528 0.347514   0.4742711 ]\n",
      "Cluster 1 mean color: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pcd is your point cloud and blossom_indices identifies the blossom points\n",
    "points = np.asarray(pcd.points)\n",
    "rgb_values = np.asarray(pcd.colors)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "scaled_points = scalar.fit_transform(points)\n",
    "\n",
    "# Extract blossom points and their colors\n",
    "blossom_points = points[blossom_indices]\n",
    "blossom_colors = rgb_values[blossom_indices]\n",
    "\n",
    "# Apply K-means clustering on blossom colors\n",
    "kmeans = KMeans(n_clusters=2, random_state=42).fit(blossom_colors)\n",
    "\n",
    "# Labels for each blossom point\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Define new colors for visualization based on clusters\n",
    "# Here, green for one cluster and black for another, adjust as needed\n",
    "cluster_colors = np.array([\n",
    "    [0, 1, 0],  # Green for the first cluster\n",
    "    [0, 0, 0]   # Black for the second cluster\n",
    "])\n",
    "\n",
    "# Apply the cluster colors to the blossom points\n",
    "segmented_blossom_colors = cluster_colors[labels]\n",
    "\n",
    "# Create a new Open3D point cloud for the segmented blossom points\n",
    "segmented_blossom_pcd = o3d.geometry.PointCloud()\n",
    "segmented_blossom_pcd.points = o3d.utility.Vector3dVector(blossom_points)\n",
    "segmented_blossom_pcd.colors = o3d.utility.Vector3dVector(segmented_blossom_colors)\n",
    "\n",
    "# Visualize the segmented blossom point cloud\n",
    "o3d.visualization.draw_geometries([segmented_blossom_pcd], window_name=\"Segmented Blossom Clustering\")\n",
    "\n",
    "# Optional: Evaluate the clusters to identify characteristics\n",
    "for i in range(2):  # For each cluster\n",
    "    cluster_mean_color = blossom_colors[labels == i].mean(axis=0)\n",
    "    print(f\"Cluster {i} mean color: {cluster_mean_color}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the point cloud\n",
    "pcd_path = 'nonground_cherry_1.pcd'\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# filter out the clear outliers\n",
    "cl, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
    "pcd = pcd.select_by_index(ind)\n",
    "\n",
    "# Compute the axis-aligned bounding box for the point cloud\n",
    "aabb = pcd.get_axis_aligned_bounding_box()\n",
    "aabb.color = (1, 0, 0)  # Red color for visualization\n",
    "\n",
    "# Visualize the point cloud and its bounding box\n",
    "# o3d.visualization.draw_geometries([pcd, aabb])\n",
    "category_to_color = {\n",
    "    1: [0, 113/255, 188/255],  # Noise\n",
    "    2: [216/255, 82/255, 24/255],  # Trunk\n",
    "    3: [236/255, 176/255, 31/255],  # Branch\n",
    "    4: [125/255, 46/255, 141/255],  # Leaf\n",
    "    5: [118/255, 171/255, 47/255],  # Blossom\n",
    "    6: [161/255, 19/255, 46/255]   # Ground\n",
    "}\n",
    "\n",
    "# load blossoms-v0.5.json\n",
    "with open('blossoms-v0.5.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "point_annotations = data['dataset']['samples'][0]['labels']['ground-truth']['attributes']['point_annotations']\n",
    "point_annotations_np = np.array(point_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average eigenvalues for blossom: [1.18708757e-06 3.01201867e-06 8.08595091e-06]\n",
      "Variance of eigenvalues for blossom: [1.22670131e-12 4.66562765e-12 2.53403754e-11]\n",
      "number of voxels: 4909\n",
      "Average eigenvalues for branch: [1.21096331e-06 3.04096311e-06 8.00344109e-06]\n",
      "Variance of eigenvalues for branch: [1.26864744e-12 4.52948563e-12 2.25185635e-11]\n",
      "number of voxels: 3900\n",
      "Average eigenvalues for trunk: [1.19075248e-06 3.03206605e-06 8.03704044e-06]\n",
      "Variance of eigenvalues for trunk: [1.19871695e-12 4.69290247e-12 2.49985518e-11]\n",
      "number of voxels: 5989\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "def analyze_voxel_shape(points):\n",
    "    \"\"\"\n",
    "    Analyze the shape of points within a voxel and return eigenvalues.\n",
    "    :param points: NumPy array of points within the voxel.\n",
    "    :return: Tuple containing a string indicating shape characteristic ('Spherical', 'Cylindrical', or 'Indeterminate')\n",
    "             and the eigenvalues of the covariance matrix of points.\n",
    "    \"\"\"\n",
    "    if len(points) < 4:  # Not enough points to form a 3D shape\n",
    "        return 'Indeterminate', np.zeros(3)\n",
    "    \n",
    "    covariance_matrix = np.cov(points.T)\n",
    "    eigenvalues, _ = np.linalg.eigh(covariance_matrix)\n",
    "    sorted_eigenvalues = np.sort(eigenvalues)\n",
    "    \n",
    "    # Shape analysis based on eigenvalues\n",
    "    if np.isclose(sorted_eigenvalues[0], sorted_eigenvalues[1]) and np.isclose(sorted_eigenvalues[1], sorted_eigenvalues[2]):\n",
    "        shape = 'Spherical'\n",
    "    elif np.isclose(sorted_eigenvalues[0], sorted_eigenvalues[1]) or np.isclose(sorted_eigenvalues[1], sorted_eigenvalues[2]):\n",
    "        shape = 'Cylindrical'\n",
    "    else:\n",
    "        shape = 'Indeterminate'\n",
    "    \n",
    "    return shape, sorted_eigenvalues\n",
    "\n",
    "\n",
    "def create_voxel_box(voxel_center, voxel_size, color=[1, 0, 0]):\n",
    "    \"\"\"\n",
    "    Create a mesh box representing a voxel at the given center with the specified size and color.\n",
    "    \n",
    "    :param voxel_center: Center of the voxel (x, y, z)\n",
    "    :param voxel_size: Size of the voxel\n",
    "    :param color: Color of the voxel\n",
    "    :return: Open3D geometry object representing the voxel box\n",
    "    \"\"\"\n",
    "    mesh_box = o3d.geometry.TriangleMesh.create_box(width=voxel_size,\n",
    "                                                    height=voxel_size,\n",
    "                                                    depth=voxel_size)\n",
    "    mesh_box.paint_uniform_color(color)\n",
    "    mesh_box.translate(voxel_center - np.array([voxel_size / 2, voxel_size / 2, voxel_size / 2]))\n",
    "    return mesh_box\n",
    "\n",
    "def classify_voxel_based_on_eigenvalues(points):\n",
    "    # Ensure points is a NumPy array for efficient computation\n",
    "    points = np.array(points)\n",
    "    \n",
    "    # Calculate the covariance matrix of points within the voxel\n",
    "    covariance_matrix = np.cov(points.T)\n",
    "    \n",
    "    # Compute eigenvalues from the covariance matrix\n",
    "    eigenvalues, _ = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    # Sort eigenvalues in ascending order\n",
    "    eigenvalues = np.sort(eigenvalues)\n",
    "    \n",
    "    # Classification logic based on eigenvalues\n",
    "    # This is a simplified example. You'll need to adjust the thresholds\n",
    "    # and logic based on the geometric characteristics of your target objects.\n",
    "    if eigenvalues[2] / eigenvalues[1] > 2 and eigenvalues[1] / eigenvalues[0] > 2:\n",
    "        # Long and thin structure, more likely a branch or trunk\n",
    "        if eigenvalues[0] < 0.01:  # Adjust threshold based on your data\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    elif eigenvalues[2] / eigenvalues[0] < 2:\n",
    "        # More spherical, could be a blossom\n",
    "        return 4\n",
    "    else:\n",
    "        # Indeterminate or other structures\n",
    "        return 2\n",
    "# Function to predict voxel label based on eigenvalues\n",
    "def predict_label(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict):\n",
    "    # Measure the difference from each category's mean, normalized by the standard deviation\n",
    "    category_scores = {}\n",
    "    for category, avg_eigenvalues in avg_eigenvalues_dict.items():\n",
    "        std_devs = std_dev_eigenvalues_dict[category]\n",
    "        # Calculate a simple score by summing the absolute differences normalized by std dev\n",
    "        score = sum(abs(eigenvalues - avg_eigenvalues) / std_devs)\n",
    "        category_scores[category] = score\n",
    "    # Predict label as the category with the minimum score\n",
    "    predicted_label = min(category_scores, key=category_scores.get)\n",
    "    return predicted_label\n",
    "\n",
    "def annotation_to_label(annotation):\n",
    "    if annotation == 4:  # Blossom\n",
    "        return 'blossom'\n",
    "    elif annotation == 2:  # Trunk\n",
    "        return 'trunk'\n",
    "    elif annotation == 3:  # Branch\n",
    "        return 'branch'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # Function to create a voxel box\n",
    "def create_voxel_box(voxel_center, voxel_size, color=[1, 0, 0]):\n",
    "    mesh_box = o3d.geometry.TriangleMesh.create_box(width=voxel_size, height=voxel_size, depth=voxel_size)\n",
    "    mesh_box.paint_uniform_color(color)\n",
    "    mesh_box.translate(voxel_center - np.array([voxel_size / 2, voxel_size / 2, voxel_size / 2]))\n",
    "    return mesh_box\n",
    "\n",
    "# Function to classify each voxel based on eigenvalues\n",
    "def classify_voxel(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict):\n",
    "    label_scores = {}\n",
    "    for label, avg_eigenvalues in avg_eigenvalues_dict.items():\n",
    "        std_dev_eigenvalues = std_dev_eigenvalues_dict[label]\n",
    "        # Calculate Z-score for each eigenvalue dimension\n",
    "        z_scores = np.abs((eigenvalues - avg_eigenvalues) / std_dev_eigenvalues)\n",
    "        # Use sum of Z-scores as the label score\n",
    "        label_scores[label] = np.sum(z_scores)\n",
    "    # Assign the label with the lowest score\n",
    "    predicted_label = min(label_scores, key=label_scores.get)\n",
    "    return predicted_label\n",
    "\n",
    "# Define color mapping for each label\n",
    "label_color_mapping = {\n",
    "    'blossom': [1, 0, 0],  # Red\n",
    "    'branch': [0, 1, 0],  # Green\n",
    "    'trunk': [0, 0, 1],  # Blue\n",
    "    'indeterminate': [0.5, 0.5, 0.5]  # Gray\n",
    "}\n",
    "\n",
    "# Predict labels for voxels and visualize\n",
    "def visualize_voxel_classification(voxel_points, voxel_size, min_bound, avg_eigenvalues_dict, std_dev_eigenvalues_dict):\n",
    "    voxel_meshes = []\n",
    "    for voxel_index, points in voxel_points.items():\n",
    "        if len(points) > 3:  # Only consider voxels with enough points\n",
    "            shape, eigenvalues = analyze_voxel_shape(np.array(points))\n",
    "            label = classify_voxel(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict)\n",
    "            color = label_color_mapping.get(label, [0.5, 0.5, 0.5])  # Default to gray if label not found\n",
    "            voxel_center = np.array([\n",
    "                min_bound[0] + (voxel_index[0] + 0.5) * voxel_size,\n",
    "                min_bound[1] + (voxel_index[1] + 0.5) * voxel_size,\n",
    "                min_bound[2] + (voxel_index[2] + 0.5) * voxel_size\n",
    "            ])\n",
    "            voxel_mesh = create_voxel_box(voxel_center, voxel_size, color)\n",
    "            voxel_meshes.append(voxel_mesh)\n",
    "    # Combine and visualize voxel meshes\n",
    "    combined_mesh = o3d.geometry.TriangleMesh()\n",
    "    for mesh in voxel_meshes:\n",
    "        combined_mesh += mesh\n",
    "    o3d.visualization.draw_geometries([combined_mesh], window_name=\"Voxel Classification\")\n",
    "\n",
    "    \n",
    "    \n",
    "# Define voxel size (sub-box size)\n",
    "voxel_size = 0.01  # For example, 1cm^3\n",
    "\n",
    "# # Get the dimensions of the bounding box\n",
    "# min_bound = aabb.get_min_bound()  # Minimum coordinates (x_min, y_min, z_min)\n",
    "# max_bound = aabb.get_max_bound()  # Maximum coordinates (x_max, y_max, z_max)\n",
    "\n",
    "# # Calculate the number of divisions along each axis\n",
    "# num_divisions_x = int(np.ceil((max_bound[0] - min_bound[0]) / voxel_size))\n",
    "# num_divisions_y = int(np.ceil((max_bound[1] - min_bound[1]) / voxel_size))\n",
    "# num_divisions_z = int(np.ceil((max_bound[2] - min_bound[2]) / voxel_size))\n",
    "\n",
    "# # Convert point cloud to NumPy array for efficient computation\n",
    "pcd_points = np.asarray(pcd.points)\n",
    "pcd_colors = np.asarray(pcd.colors)  # If color analysis is needed\n",
    "\n",
    "# # Initialize a 3D array to hold the count of points in each voxel\n",
    "# voxel_grid = np.zeros((num_divisions_x, num_divisions_y, num_divisions_z))\n",
    "\n",
    "# # Iterate through each voxel and count points\n",
    "# for point in pcd_points:\n",
    "#     # Determine the voxel in which the point falls\n",
    "#     index_x = int((point[0] - min_bound[0]) / voxel_size)\n",
    "#     index_y = int((point[1] - min_bound[1]) / voxel_size)\n",
    "#     index_z = int((point[2] - min_bound[2]) / voxel_size)\n",
    "    \n",
    "#     # Increment the count of points in this voxel\n",
    "#     voxel_grid[index_x, index_y, index_z] += 1\n",
    "#     # Function to create a box mesh\n",
    "\n",
    "\n",
    "# # Initialize a list to hold the voxel box meshes\n",
    "# voxel_meshes = []\n",
    "\n",
    "# # Iterate through the voxel grid to create boxes for non-empty voxels\n",
    "# for ix in range(num_divisions_x):\n",
    "#     for iy in range(num_divisions_y):\n",
    "#         for iz in range(num_divisions_z):\n",
    "#             if voxel_grid[ix, iy, iz] > 0:  # Check if the voxel contains any points\n",
    "#                 # Calculate the center of the voxel\n",
    "#                 voxel_center = np.array([min_bound[0] + (ix + 0.5) * voxel_size,\n",
    "#                                          min_bound[1] + (iy + 0.5) * voxel_size,\n",
    "#                                          min_bound[2] + (iz + 0.5) * voxel_size])\n",
    "                \n",
    "#                 # Create a voxel box mesh\n",
    "#                 voxel_mesh = create_voxel_box(voxel_center, voxel_size, color=[0.8, 0.8, 0.8])  # Light gray color\n",
    "#                 voxel_meshes.append(voxel_mesh)\n",
    "\n",
    "# # Combine all voxel meshes into a single mesh (for efficiency)\n",
    "# combined_mesh = voxel_meshes[0]\n",
    "# for mesh in voxel_meshes[1:]:\n",
    "#     combined_mesh += mesh\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the combined mesh\n",
    "# o3d.visualization.draw_geometries([combined_mesh], window_name='Voxel Grid Visualization')\n",
    "    \n",
    "# Calculate the 75th percentile of points per non-empty voxel\n",
    "# non_empty_voxels = voxel_grid[voxel_grid > 0]\n",
    "# points_per_voxel_75th_percentile = np.percentile(non_empty_voxels, 75)\n",
    "\n",
    "# Initialize labels for each voxel: 1 for above 75th percentile, 0 for below\n",
    "# voxel_labels = np.zeros_like(voxel_grid)\n",
    "\n",
    "# # Label voxels based on comparison with the 75th percentile\n",
    "# for ix in range(num_divisions_x):\n",
    "#     for iy in range(num_divisions_y):\n",
    "#         for iz in range(num_divisions_z):\n",
    "#             if voxel_grid[ix, iy, iz] > 0:  # Only consider non-empty voxels\n",
    "#                 if voxel_grid[ix, iy, iz] > points_per_voxel_75th_percentile:\n",
    "#                     voxel_labels[ix, iy, iz] = 1  # Above 75th percentile\n",
    "#                 else:\n",
    "#                     voxel_labels[ix, iy, iz] = 0  # Below 75th percentile\n",
    "\n",
    "# # Colors for visualization\n",
    "# color_above_mean = [0, 1, 0]  # Green for voxels above the mean\n",
    "# color_below_mean = [1, 0, 0]  # Red for voxels below the mean\n",
    "\n",
    "# # Initialize lists to hold voxel box meshes for different labels\n",
    "# voxel_meshes_above_mean = []\n",
    "# voxel_meshes_below_mean = []\n",
    "\n",
    "# # Iterate through the labeled voxel grid and create box meshes with corresponding colors\n",
    "# for ix in range(num_divisions_x):\n",
    "#     for iy in range(num_divisions_y):\n",
    "#         for iz in range(num_divisions_z):\n",
    "#             if voxel_grid[ix, iy, iz] > 0:  # Only consider non-empty voxels\n",
    "#                 voxel_center = np.array([min_bound[0] + (ix + 0.5) * voxel_size,\n",
    "#                                          min_bound[1] + (iy + 0.5) * voxel_size,\n",
    "#                                          min_bound[2] + (iz + 0.5) * voxel_size])\n",
    "#                 if voxel_labels[ix, iy, iz] == 1:\n",
    "#                     voxel_mesh = create_voxel_box(voxel_center, voxel_size, color=color_above_mean)\n",
    "#                     voxel_meshes_above_mean.append(voxel_mesh)\n",
    "#                 else:\n",
    "#                     voxel_mesh = create_voxel_box(voxel_center, voxel_size, color=color_below_mean)\n",
    "#                     voxel_meshes_below_mean.append(voxel_mesh)\n",
    "\n",
    "# # Combine voxel meshes from both categories into single meshes for more efficient visualization\n",
    "# combined_mesh_above_mean = voxel_meshes_above_mean[0]\n",
    "# for mesh in voxel_meshes_above_mean[1:]:\n",
    "#     combined_mesh_above_mean += mesh\n",
    "\n",
    "# combined_mesh_below_mean = voxel_meshes_below_mean[0]\n",
    "# for mesh in voxel_meshes_below_mean[1:]:\n",
    "#     combined_mesh_below_mean += mesh\n",
    "\n",
    "# print(len(voxel_meshes_above_mean))\n",
    "\n",
    "# Visualize the combined meshes\n",
    "# o3d.visualization.draw_geometries([combined_mesh_above_mean, combined_mesh_below_mean], window_name='Voxel Grid Visualization by Mean Point Count')\n",
    "\n",
    "# Assuming `point_annotations_np` contains the label for each point\n",
    "# and `pcd_points` is the array of point positions\n",
    "\n",
    "# # Initialize arrays to hold point counts for blossom, branch, and trunk voxels\n",
    "# blossom_voxel_counts = []\n",
    "# branch_voxel_counts = []\n",
    "# trunk_voxel_counts = []\n",
    "\n",
    "# # Initialize a 3D grid to classify voxels\n",
    "# voxel_classification = np.zeros((num_divisions_x, num_divisions_y, num_divisions_z))\n",
    "\n",
    "# # Iterate over each point to classify voxels\n",
    "# for i, point in enumerate(pcd_points):\n",
    "#     label = point_annotations_np[i]\n",
    "#     index_x = int((point[0] - min_bound[0]) / voxel_size)\n",
    "#     index_y = int((point[1] - min_bound[1]) / voxel_size)\n",
    "#     index_z = int((point[2] - min_bound[2]) / voxel_size)\n",
    "    \n",
    "#     # Classify the voxel based on the point label\n",
    "#     if label == 4:  # Blossom\n",
    "#         if voxel_classification[index_x, index_y, index_z] != 4:\n",
    "#             voxel_classification[index_x, index_y, index_z] = 4\n",
    "#             blossom_voxel_counts.append(1)\n",
    "#         else:\n",
    "#             blossom_voxel_counts[-1] += 1  # Increment the last count\n",
    "#     elif label == 2:  # Trunk\n",
    "#         if voxel_classification[index_x, index_y, index_z] != 2:\n",
    "#             voxel_classification[index_x, index_y, index_z] = 2\n",
    "#             trunk_voxel_counts.append(1)\n",
    "#         else:\n",
    "#             trunk_voxel_counts[-1] += 1\n",
    "#     elif label == 3:  # Branch\n",
    "#         if voxel_classification[index_x, index_y, index_z] != 3:\n",
    "#             voxel_classification[index_x, index_y, index_z] = 3\n",
    "#             branch_voxel_counts.append(1)\n",
    "#         else:\n",
    "#             branch_voxel_counts[-1] += 1\n",
    "\n",
    "# mean_density_blossom = np.mean(blossom_voxel_counts) if blossom_voxel_counts else 0\n",
    "# mean_density_branch = np.mean(branch_voxel_counts) if branch_voxel_counts else 0\n",
    "# mean_density_trunk = np.mean(trunk_voxel_counts) if trunk_voxel_counts else 0\n",
    "\n",
    "# print(f\"Mean Density of Blossoms: {mean_density_blossom}\")\n",
    "# print(f\"Mean Density of Branches: {mean_density_branch}\")\n",
    "# print(f\"Mean Density of Trunks: {mean_density_trunk}\")\n",
    "\n",
    "\n",
    "# # Calculate the variance and standard deviation for each category\n",
    "# variance_density_blossom = np.var(blossom_voxel_counts) if blossom_voxel_counts else 0\n",
    "# std_dev_density_blossom = np.std(blossom_voxel_counts) if blossom_voxel_counts else 0\n",
    "\n",
    "# variance_density_branch = np.var(branch_voxel_counts) if branch_voxel_counts else 0\n",
    "# std_dev_density_branch = np.std(branch_voxel_counts) if branch_voxel_counts else 0\n",
    "\n",
    "# variance_density_trunk = np.var(trunk_voxel_counts) if trunk_voxel_counts else 0\n",
    "# std_dev_density_trunk = np.std(trunk_voxel_counts) if trunk_voxel_counts else 0\n",
    "\n",
    "# print(f\"Variance in Density of Blossoms: {variance_density_blossom}, Standard Deviation: {std_dev_density_blossom}\")\n",
    "# print(f\"Variance in Density of Branches: {variance_density_branch}, Standard Deviation: {std_dev_density_branch}\")\n",
    "# print(f\"Variance in Density of Trunks: {variance_density_trunk}, Standard Deviation: {std_dev_density_trunk}\")\n",
    "\n",
    "\n",
    "\n",
    "min_bound = pcd.get_min_bound()\n",
    "max_bound = pcd.get_max_bound()\n",
    "num_divisions_x = int(np.ceil((max_bound[0] - min_bound[0]) / voxel_size))\n",
    "num_divisions_y = int(np.ceil((max_bound[1] - min_bound[1]) / voxel_size))\n",
    "num_divisions_z = int(np.ceil((max_bound[2] - min_bound[2]) / voxel_size))\n",
    "\n",
    "# Initialize dictionaries for voxel classification and points storage\n",
    "voxel_classification = {}  # Maps voxel indices to labels based on contained points\n",
    "voxel_points = {}  # Stores points for each voxel\n",
    "# scalar = StandardScaler()\n",
    "# scaled_points = scalar.fit_transform(pcd_points)\n",
    "# Classify each point and aggregate in voxel_points\n",
    "for i, point in enumerate(pcd_points):\n",
    "    voxel_index = (int((point[0] - min_bound[0]) / voxel_size),\n",
    "                   int((point[1] - min_bound[1]) / voxel_size),\n",
    "                   int((point[2] - min_bound[2]) / voxel_size))\n",
    "    label = annotation_to_label(point_annotations_np[i])  # Hypothetical function\n",
    "    voxel_points.setdefault(voxel_index, []).append(point)\n",
    "    # Update voxel classification based on annotations; refine this logic as needed\n",
    "    voxel_classification[voxel_index] = label\n",
    "\n",
    "# Analyze shape and calculate eigenvalues for each classified voxel\n",
    "eigenvalues_dict = {'blossom': [], 'branch': [], 'trunk': []}\n",
    "avg_eigenvalues_dict = {}\n",
    "std_dev_eigenvalues_dict = {}\n",
    "\n",
    "for voxel_index, points in voxel_points.items():\n",
    "    if len(points) > 3:  # Ensure there are enough points for shape analysis\n",
    "        _, eigenvalues = analyze_voxel_shape(np.array(points))\n",
    "        label = voxel_classification.get(voxel_index)\n",
    "        if label:\n",
    "            eigenvalues_dict[label].append(eigenvalues)\n",
    "\n",
    "# Calculate and print average eigenvalues for each label\n",
    "for label, eigenvalues_list in eigenvalues_dict.items():\n",
    "    if eigenvalues_list:\n",
    "        avg_eigenvalues = np.mean(eigenvalues_list, axis=0)\n",
    "        variance_eigenvalues = np.var(eigenvalues_list, axis=0)\n",
    "        avg_eigenvalues_dict[label] = avg_eigenvalues\n",
    "        std_dev_eigenvalues_dict[label] = np.sqrt(variance_eigenvalues)\n",
    "        print(f\"Average eigenvalues for {label}: {avg_eigenvalues}\")\n",
    "        print(f\"Variance of eigenvalues for {label}: {variance_eigenvalues}\")\n",
    "        print('number of voxels:', len(eigenvalues_list))\n",
    "    else:\n",
    "        print(f\"No data for {label}\")\n",
    "\n",
    "\n",
    "visualize_voxel_classification(voxel_points, voxel_size, min_bound, avg_eigenvalues_dict, std_dev_eigenvalues_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create a dictionary to hold points for each voxel for shape analysis\n",
    "# # Recalculate min and max bounds if necessary\n",
    "# min_bound = np.min(pcd_points, axis=0)\n",
    "# max_bound = np.max(pcd_points, axis=0)\n",
    "\n",
    "# # Calculate the number of divisions along each axis again if necessary\n",
    "# num_divisions_x = int(np.ceil((max_bound[0] - min_bound[0]) / voxel_size))\n",
    "# num_divisions_y = int(np.ceil((max_bound[1] - min_bound[1]) / voxel_size))\n",
    "# num_divisions_z = int(np.ceil((max_bound[2] - min_bound[2]) / voxel_size))\n",
    "\n",
    "# # Reinitialize voxel_points dictionary to avoid KeyError\n",
    "# voxel_points = {(x, y, z): [] for x in range(num_divisions_x) for y in range(num_divisions_y) for z in range(num_divisions_z)}\n",
    "\n",
    "# # Populate voxel_points with actual points, ensuring indices are within bounds\n",
    "# for i, point in enumerate(pcd_points):\n",
    "#     index_x = min(max(int((point[0] - min_bound[0]) / voxel_size), 0), num_divisions_x - 1)\n",
    "#     index_y = min(max(int((point[1] - min_bound[1]) / voxel_size), 0), num_divisions_y - 1)\n",
    "#     index_z = min(max(int((point[2] - min_bound[2]) / voxel_size), 0), num_divisions_z - 1)\n",
    "#     voxel_points[(index_x, index_y, index_z)].append(point)\n",
    "\n",
    "# # Analyze shape for each voxel and classify\n",
    "# voxel_shape_classification = {}\n",
    "# for voxel_index, points in voxel_points.items():\n",
    "#     if points:  # If there are points in the voxel\n",
    "#         shape = analyze_voxel_shape(np.array(points))\n",
    "#         voxel_shape_classification[voxel_index] = shape\n",
    "\n",
    "# # Use different colors for different classifications\n",
    "# shape_colors = {\n",
    "#     'Spherical': [0, 1, 0],  # Green\n",
    "#     'Cylindrical': [0, 0, 1],  # Blue\n",
    "#     'Indeterminate': [1, 0, 0]  # Red\n",
    "# }\n",
    "# # Function to map annotations to labels (for demonstration purposes)\n",
    "# def annotation_to_label(annotation):\n",
    "#     if annotation == 4:  # Blossom\n",
    "#         return 'blossom'\n",
    "#     elif annotation == 2:  # Trunk\n",
    "#         return 'trunk'\n",
    "#     elif annotation == 3:  # Branch\n",
    "#         return 'branch'\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Calculate eigenvalues for each voxel's points and classify shape\n",
    "# eigenvalues_dict = {'blossom': [], 'branch': [], 'trunk': []}\n",
    "\n",
    "# # Iterate through each voxel to analyze shape and store eigenvalues\n",
    "# for ix in range(num_divisions_x):\n",
    "#     for iy in range(num_divisions_y):\n",
    "#         for iz in range(num_divisions_z):\n",
    "#             voxel_points = pcd_points[(voxel_grid[index_x, index_y, index_z] > 0)]\n",
    "#             if len(voxel_points) > 3:\n",
    "#                 shape, eigenvalues = analyze_voxel_shape(voxel_points)\n",
    "#                 # Example: Directly using the first point's annotation as voxel's label, adjust as needed\n",
    "#                 label = annotation_to_label(point_annotations_np[ix][iy][iz])\n",
    "#                 if label:\n",
    "#                     eigenvalues_dict[label].append(eigenvalues)\n",
    "\n",
    "# # Calculate average eigenvalues for each classification\n",
    "# for label, eigenvalues_list in eigenvalues_dict.items():\n",
    "#     if eigenvalues_list:\n",
    "#         avg_eigenvalues = np.mean(eigenvalues_list, axis=0)\n",
    "#         print(f\"Average eigenvalues for {label}: {avg_eigenvalues}\")\n",
    "#     else:\n",
    "#         print(f\"No data for {label}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify_voxel_based_on_eigenvalues(points):\n",
    "#     # Ensure points is a NumPy array for efficient computation\n",
    "#     points = np.array(points)\n",
    "    \n",
    "#     # Calculate the covariance matrix of points within the voxel\n",
    "#     covariance_matrix = np.cov(points.T)\n",
    "    \n",
    "#     # Compute eigenvalues from the covariance matrix\n",
    "#     eigenvalues, _ = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "#     # Sort eigenvalues in ascending order\n",
    "#     eigenvalues = np.sort(eigenvalues)\n",
    "    \n",
    "#     # Classification logic based on eigenvalues\n",
    "#     # This is a simplified example. You'll need to adjust the thresholds\n",
    "#     # and logic based on the geometric characteristics of your target objects.\n",
    "#     if eigenvalues[2] / eigenvalues[1] > 2 and eigenvalues[1] / eigenvalues[0] > 2:\n",
    "#         # Long and thin structure, more likely a branch or trunk\n",
    "#         if eigenvalues[0] < 0.01:  # Adjust threshold based on your data\n",
    "#             return 2\n",
    "#         else:\n",
    "#             return 3\n",
    "#     elif eigenvalues[2] / eigenvalues[0] < 2:\n",
    "#         # More spherical, could be a blossom\n",
    "#         return 4\n",
    "#     else:\n",
    "#         # Indeterminate or other structures\n",
    "#         return 2\n",
    "# # Function to predict voxel label based on eigenvalues\n",
    "# def predict_label(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict):\n",
    "#     # Measure the difference from each category's mean, normalized by the standard deviation\n",
    "#     category_scores = {}\n",
    "#     for category, avg_eigenvalues in avg_eigenvalues_dict.items():\n",
    "#         std_devs = std_dev_eigenvalues_dict[category]\n",
    "#         # Calculate a simple score by summing the absolute differences normalized by std dev\n",
    "#         score = sum(abs(eigenvalues - avg_eigenvalues) / std_devs)\n",
    "#         category_scores[category] = score\n",
    "#     # Predict label as the category with the minimum score\n",
    "#     predicted_label = min(category_scores, key=category_scores.get)\n",
    "#     return predicted_label\n",
    "\n",
    "# # Visualization based on predicted labels\n",
    "# for voxel_index, points in voxel_points.items():\n",
    "#     if len(points) > 3:\n",
    "#         _, eigenvalues = analyze_voxel_shape(np.array(points))\n",
    "#         predicted_label = predict_label(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict)\n",
    "#         color = category_to_color(predicted_label)\n",
    "#         voxel_center = np.array([\n",
    "#             min_bound[0] + (voxel_index[0] + 0.5) * voxel_size,\n",
    "#             min_bound[1] + (voxel_index[1] + 0.5) * voxel_size,\n",
    "#             min_bound[2] + (voxel_index[2] + 0.5) * voxel_size\n",
    "#         ])\n",
    "#         voxel_mesh = create_voxel_box(voxel_center, voxel_size, color)\n",
    "#         voxel_meshes.append(voxel_mesh)\n",
    "\n",
    "# # Combine and visualize all voxel meshes\n",
    "# combined_mesh = voxel_meshes[0]\n",
    "# for mesh in voxel_meshes[1:]:\n",
    "#     combined_mesh += mesh\n",
    "# o3d.visualization.draw_geometries([combined_mesh], window_name=\"Voxel Classification Visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Assuming the necessary preliminary steps are done and eigenvalues_dict is populated\n",
    "\n",
    "# Function to classify voxels based on eigenvalues within 2 standard deviations\n",
    "def classify_voxel(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict):\n",
    "    for label, avg_eigenvalues in avg_eigenvalues_dict.items():\n",
    "        std_dev_eigenvalues = std_dev_eigenvalues_dict[label]\n",
    "        if np.all(np.abs(eigenvalues - avg_eigenvalues) <= 2 * std_dev_eigenvalues):\n",
    "            return label\n",
    "    return 'indeterminate'\n",
    "\n",
    "# Function to visualize voxels\n",
    "def visualize_voxels(voxel_labels, voxel_size, min_bound):\n",
    "    voxel_meshes = []\n",
    "    for voxel_index, label in voxel_labels.items():\n",
    "        center = np.array([min_bound[0] + (voxel_index[0] + 0.5) * voxel_size,\n",
    "                           min_bound[1] + (voxel_index[1] + 0.5) * voxel_size,\n",
    "                           min_bound[2] + (voxel_index[2] + 0.5) * voxel_size])\n",
    "        color = [0.5, 0.5, 0.5]  # Default color for indeterminate\n",
    "        if label == 'blossom':\n",
    "            color = [1, 0, 0]\n",
    "        elif label == 'branch':\n",
    "            color = [0, 1, 0]\n",
    "        elif label == 'trunk':\n",
    "            color = [0, 0, 1]\n",
    "        mesh = create_voxel_box(center, voxel_size, color)\n",
    "        voxel_meshes.append(mesh)\n",
    "    o3d.visualization.draw_geometries(voxel_meshes, window_name=\"Voxel Classification\")\n",
    "\n",
    "# Calculate average and standard deviation for each category\n",
    "avg_eigenvalues_dict = {label: np.mean(values, axis=0) for label, values in eigenvalues_dict.items()}\n",
    "std_dev_eigenvalues_dict = {label: np.std(values, axis=0) for label, values in eigenvalues_dict.items()}\n",
    "\n",
    "# Predict labels for each voxel and visualize\n",
    "voxel_labels = {}\n",
    "for voxel_index, points in voxel_points.items():\n",
    "    if len(points) > 3:  # Only consider voxels with enough points\n",
    "        _, eigenvalues = analyze_voxel_shape(np.array(points))\n",
    "        label = classify_voxel(eigenvalues, avg_eigenvalues_dict, std_dev_eigenvalues_dict)\n",
    "        voxel_labels[voxel_index] = label\n",
    "\n",
    "visualize_voxels(voxel_labels, voxel_size, min_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate mean and standard deviation for eigenvalues\n",
    "def calc_mean_std(eigenvalues_list):\n",
    "    mean_eigenvalues = np.mean(eigenvalues_list, axis=0)\n",
    "    std_dev_eigenvalues = np.std(eigenvalues_list, axis=0)\n",
    "    return mean_eigenvalues, std_dev_eigenvalues\n",
    "\n",
    "# Calculate mean and standard deviation for each category\n",
    "mean_std_dict = {label: calc_mean_std(eigenvalues_list) for label, eigenvalues_list in eigenvalues_dict.items()}\n",
    "\n",
    "# Function to classify voxels based on eigenvalues\n",
    "def classify_voxel(eigenvalues, mean_std_dict):\n",
    "    for label, (mean_eigenvalues, std_dev_eigenvalues) in mean_std_dict.items():\n",
    "        if np.all(np.abs(eigenvalues - mean_eigenvalues) <= 2 * std_dev_eigenvalues):\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "# Classify each voxel and store the result\n",
    "voxel_labels = {}\n",
    "for voxel_index, points in voxel_points.items():\n",
    "    if len(points) > 3:  # Ensure there are enough points for shape analysis\n",
    "        _, eigenvalues = analyze_voxel_shape(np.array(points))\n",
    "        voxel_labels[voxel_index] = classify_voxel(eigenvalues, mean_std_dict)\n",
    "\n",
    "# Visualization\n",
    "voxel_meshes = []\n",
    "for voxel_index, label in voxel_labels.items():\n",
    "    voxel_center = np.array([min_bound[0] + (voxel_index[0] + 0.5) * voxel_size,\n",
    "                             min_bound[1] + (voxel_index[1] + 0.5) * voxel_size,\n",
    "                             min_bound[2] + (voxel_index[2] + 0.5) * voxel_size])\n",
    "    color = [0.5, 0.5, 0.5]  # Default color for indeterminate\n",
    "    if label == 'blossom':\n",
    "        color = [1, 0, 0]  # Red for blossom\n",
    "    elif label == 'branch':\n",
    "        color = [0, 1, 0]  # Green for branch\n",
    "    elif label == 'trunk':\n",
    "        color = [0, 0, 1]  # Blue for trunk\n",
    "    voxel_mesh = create_voxel_box(voxel_center, voxel_size, color)\n",
    "    voxel_meshes.append(voxel_mesh)\n",
    "\n",
    "# Combine and visualize\n",
    "combined_mesh = voxel_meshes[0]\n",
    "for mesh in voxel_meshes[1:]:\n",
    "    combined_mesh += mesh\n",
    "o3d.visualization.draw_geometries([combined_mesh], window_name=\"Voxel Classification\")\n",
    "# Initialize lists to accumulate RGB values for each category\n",
    "blossom_rgb_values = []\n",
    "branch_rgb_values = []\n",
    "trunk_rgb_values = []\n",
    "\n",
    "# Iterate over each point to classify voxels and accumulate RGB values\n",
    "for i, point in enumerate(pcd_points):\n",
    "    label = point_annotations_np[i]\n",
    "    index_x = int((point[0] - min_bound[0]) / voxel_size)\n",
    "    index_y = int((point[1] - min_bound[1]) / voxel_size)\n",
    "    index_z = int((point[2] - min_bound[2]) / voxel_size)\n",
    "    \n",
    "    # Accumulate RGB values based on the point label\n",
    "    if label == 4:  # Blossom\n",
    "        blossom_rgb_values.append(pcd_colors[i])\n",
    "    elif label == 2:  # Trunk\n",
    "        trunk_rgb_values.append(pcd_colors[i])\n",
    "    elif label == 3:  # Branch\n",
    "        branch_rgb_values.append(pcd_colors[i])\n",
    "\n",
    "# Convert lists to numpy arrays for efficient computation\n",
    "blossom_rgb_values = np.array(blossom_rgb_values)\n",
    "branch_rgb_values = np.array(branch_rgb_values)\n",
    "trunk_rgb_values = np.array(trunk_rgb_values)\n",
    "\n",
    "# Calculate the mean RGB values for each category\n",
    "mean_rgb_blossom = np.mean(blossom_rgb_values, axis=0) if blossom_rgb_values.size else [0, 0, 0]\n",
    "mean_rgb_branch = np.mean(branch_rgb_values, axis=0) if branch_rgb_values.size else [0, 0, 0]\n",
    "mean_rgb_trunk = np.mean(trunk_rgb_values, axis=0) if trunk_rgb_values.size else [0, 0, 0]\n",
    "\n",
    "print(f\"Mean RGB of Blossoms: {mean_rgb_blossom}\")\n",
    "print(f\"Mean RGB of Branches: {mean_rgb_branch}\")\n",
    "print(f\"Mean RGB of Trunks: {mean_rgb_trunk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2*(-lambda_1 + lambda_2)*(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**2*x(t) + (Derivative(x(t), t)*Derivative(x(t), (t, 2)) + Derivative(y(t), t)*Derivative(y(t), (t, 2)) + Derivative(z(t), t)*Derivative(z(t), (t, 2)))*sqrt(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)*Derivative(x(t), t) - (Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**(3/2)*Derivative(x(t), (t, 2)))/(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**2,\n",
       " (2*(-lambda_1 + lambda_2)*(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**2*y(t) + (Derivative(x(t), t)*Derivative(x(t), (t, 2)) + Derivative(y(t), t)*Derivative(y(t), (t, 2)) + Derivative(z(t), t)*Derivative(z(t), (t, 2)))*sqrt(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)*Derivative(y(t), t) - (Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**(3/2)*Derivative(y(t), (t, 2)))/(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**2,\n",
       " (2*(-lambda_1 + lambda_2)*(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**2*z(t) + (Derivative(x(t), t)*Derivative(x(t), (t, 2)) + Derivative(y(t), t)*Derivative(y(t), (t, 2)) + Derivative(z(t), t)*Derivative(z(t), (t, 2)))*sqrt(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)*Derivative(z(t), t) - (Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**(3/2)*Derivative(z(t), (t, 2)))/(Derivative(x(t), t)**2 + Derivative(y(t), t)**2 + Derivative(z(t), t)**2)**2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# Define symbolic variables\n",
    "t = sp.symbols('t')\n",
    "x = sp.Function('x')(t)\n",
    "y = sp.Function('y')(t)\n",
    "z = sp.Function('z')(t)\n",
    "dx = x.diff(t)\n",
    "dy = y.diff(t)\n",
    "dz = z.diff(t)\n",
    "lambda_1, lambda_2, r, R = sp.symbols('lambda_1 lambda_2 r R')\n",
    "\n",
    "# Define the Lagrangian with the inequality constraints incorporated\n",
    "L = sp.sqrt(dx**2 + dy**2 + dz**2)\n",
    "constraint1 = r**2 - x**2 - y**2 - z**2  # r^2 <= x^2 + y^2 + z^2\n",
    "constraint2 = x**2 + y**2 + z**2 - R**2  # x^2 + y^2 + z^2 <= R^2\n",
    "\n",
    "# Incorporate constraints using Lagrange multipliers\n",
    "Lagrangian = L + lambda_1*constraint1 + lambda_2*constraint2\n",
    "\n",
    "# Compute the Euler-Lagrange equations\n",
    "euler_lagrange_eqns = []\n",
    "for var in [x, y, z]:\n",
    "    dL_dvar = Lagrangian.diff(var)\n",
    "    dL_ddotvar = Lagrangian.diff(var.diff(t))\n",
    "    euler_lagrange_eqn = dL_dvar - sp.diff(dL_ddotvar, t)\n",
    "    euler_lagrange_eqns.append(euler_lagrange_eqn)\n",
    "\n",
    "# Display the Euler-Lagrange equations and their derivatives set to zero\n",
    "euler_lagrange_eqns_simplified = [eqn.simplify() for eqn in euler_lagrange_eqns]\n",
    "euler_lagrange_eqns_simplified\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
